"""
AI Watermark Remover - æ¨¡å—åŒ–ä¸»å…¥å£
æ•´åˆé…ç½®ã€UIã€æ¨ç†å’Œå›¾åƒå¤„ç†æ¨¡å—
"""

import sys
import os
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import streamlit as st
import logging
from PIL import Image

# å¯¼å…¥æ¨¡å—
from config.config import ConfigManager
from interfaces.web.ui import MainInterface
from core.inference import get_inference_manager, get_system_info

# é…ç½®é¡µé¢
def setup_page_config(config_manager):
    """è®¾ç½®é¡µé¢é…ç½®"""
    app_config = config_manager.app_config
    st.set_page_config(
        page_title=app_config.page_title,
        page_icon=app_config.page_icon,
        layout=app_config.layout,
        initial_sidebar_state=app_config.initial_sidebar_state
    )

# é…ç½®æ—¥å¿—
def setup_logging():
    """é…ç½®æ—¥å¿—"""
    logging.basicConfig(level=logging.INFO)
    return logging.getLogger(__name__)

# åˆå§‹åŒ–session state
def init_session_state():
    """åˆå§‹åŒ–session state"""
    if 'processor' not in st.session_state:
        st.session_state.processor = None
    if 'processing_result' not in st.session_state:
        st.session_state.processing_result = None
    if 'original_image' not in st.session_state:
        st.session_state.original_image = None
    if 'last_parameters' not in st.session_state:
        st.session_state.last_parameters = {}
    if 'current_parameters' not in st.session_state:
        st.session_state.current_parameters = None

# åŠ è½½å¤„ç†å™¨
def load_processor(config_manager):
    """åŠ è½½å¤„ç†å™¨"""
    if st.session_state.processor is None:
        with st.spinner("Loading AI models..."):
            try:
                inference_manager = get_inference_manager(config_manager)
                if inference_manager is not None:
                    st.session_state.processor = inference_manager
                    st.success("âœ… AI models loaded successfully!")
                    return True
                else:
                    st.error("âŒ Failed to load models")
                    return False
            except Exception as e:
                st.error(f"âŒ Failed to load models: {e}")
                return False
    return True

# è·å–å¤„ç†å™¨
def get_processor():
    """è·å–å¤„ç†å™¨"""
    return st.session_state.processor

# ä¸»åº”ç”¨å‡½æ•°
def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    config_manager = ConfigManager()
    
    # è®¾ç½®é¡µé¢é…ç½®
    setup_page_config(config_manager)
    
    # åˆå§‹åŒ–session state
    init_session_state()
    
    # åˆå§‹åŒ–ä¸»ç•Œé¢
    main_interface = MainInterface(config_manager)
    
    # åŠ è½½å¤„ç†å™¨
    if not load_processor(config_manager):
        st.error("âŒ Failed to initialize AI models. Please check:")
        st.error("1. Model files exist in the correct paths")
        st.error("2. Dependencies are properly installed") 
        st.error("3. CUDA/GPU setup if using GPU acceleration")
        st.stop()
    
    # æ¸²æŸ“ä¸»ç•Œé¢
    main_interface.render(
        inference_manager=get_processor(),
        processing_result=st.session_state.processing_result
    )
    
    # é¡µè„šä¿¡æ¯
    st.divider()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.caption("ğŸ”¬ Debug Edition")
    with col2:
        st.caption("âš¡ Real-time Parameters")  
    with col3:
        st.caption("ğŸ”„ Interactive Comparison")

if __name__ == "__main__":
    main() 