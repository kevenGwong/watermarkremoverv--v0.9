# PowerPaint v2 + Realistic Vision V1.4-inpainting å®‰è£…éƒ¨ç½²æŒ‡å—

## ðŸŽ¯ **é¡¹ç›®ç›®æ ‡**

åœ¨ PowerPaint v2 æ¡†æž¶ä¸‹ï¼Œä½¿ç”¨è½»é‡ç‰ˆæ¨¡åž‹ Realistic Vision V1.4-inpainting å®žçŽ°è‡ªå®šä¹‰ mask çš„å•†å“å›¾åŽ»æ°´å°åŠŸèƒ½ï¼Œé€‚é…æœ¬åœ° GPU æŽ¨ç†ã€‚

### âœ… **æ ¸å¿ƒç›®æ ‡**
- ä½¿ç”¨è‡ªå®šä¹‰ maskï¼Œç²¾å‡†ä¿®å¤æ°´å°åŒºåŸŸ
- æ›¿æ¢ PowerPaint é»˜è®¤é‡åž‹æ¨¡åž‹ â†’ ä½¿ç”¨ HuggingFace ä¸Šçš„è½»é‡é«˜è´¨é‡æ¨¡åž‹
- ä¿ç•™ PowerPaint v2 çš„ CLI / UI / æŽ¨ç†å…¼å®¹ç»“æž„
- å¯åœ¨æœ¬åœ° GPUï¼ˆå¦‚ Tesla T4, RTX 3060, 4060ï¼‰ä¸Šè¿è¡Œ
- æ”¯æŒæœªæ¥åˆ‡æ¢å…¶ä»– SD1.5 inpainting æ¨¡åž‹

## ðŸ”§ **ç³»ç»Ÿè¦æ±‚**

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU with 8GB+ VRAM (æŽ¨è)
  - Tesla T4 (8GB) âœ…
  - RTX 3060 (12GB) âœ…
  - RTX 4060 (8GB) âœ…
  - RTX 4090 (24GB) âœ…
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´

### è½¯ä»¶è¦æ±‚
- **Python**: 3.8-3.11
- **CUDA**: 11.8+ (æŽ¨è 12.1+)
- **PyTorch**: 2.0+ with CUDA support

## ðŸ“¦ **å®‰è£…æ­¥éª¤**

### 1. çŽ¯å¢ƒå‡†å¤‡

```bash
# æ¿€æ´»condaçŽ¯å¢ƒ
conda activate py310aiwatermark

# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}')"
```

### 2. å®‰è£…PowerPaint v2ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install diffusers transformers accelerate safetensors

# å®‰è£…PowerPaint v2
pip install git+https://github.com/open-mmlab/PowerPaint.git

# å®‰è£…IOPaint (å¦‚æžœæœªå®‰è£…)
pip install iopaint>=1.6.0
```

### 3. ä¸‹è½½Realistic Vision V1.4-inpaintingæ¨¡åž‹

```bash
# åˆ›å»ºæ¨¡åž‹ç›®å½•
mkdir -p models/powerpaint_v2
cd models/powerpaint_v2

# ä¸‹è½½æ¨¡åž‹ (ä½¿ç”¨git-lfs)
git lfs install
git clone https://huggingface.co/Sanster/Realistic_Vision_V1.4-inpainting
### è‹¥éœ€è¦huggingface token , åˆ™å¡«å…¥REMOVED_TOKEN
# æˆ–è€…ä½¿ç”¨huggingface_hub
pip install huggingface_hub
python -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='Sanster/Realistic_Vision_V1.4-inpainting',
    local_dir='./Realistic_Vision_V1.4-inpainting',
    local_dir_use_symlinks=False
)
"
```

### 4. éªŒè¯å®‰è£…

```bash
# æµ‹è¯•æ¨¡åž‹åŠ è½½
python -c "
import torch
from diffusers import StableDiffusionInpaintPipeline

# åŠ è½½æ¨¡åž‹
pipe = StableDiffusionInpaintPipeline.from_pretrained(
    './models/powerpaint_v2/Realistic_Vision_V1.4-inpainting',
    torch_dtype=torch.float16,
    use_safetensors=True
)

# ç§»åŠ¨åˆ°GPU
pipe = pipe.to('cuda')
print('âœ… Realistic Vision V1.4-inpainting åŠ è½½æˆåŠŸ!')
print(f'æ¨¡åž‹è®¾å¤‡: {pipe.device}')
print(f'æ¨¡åž‹ç²¾åº¦: {pipe.unet.dtype}')
"
```

## ðŸ—ï¸ **é¡¹ç›®é›†æˆ**

### 1. åˆ›å»ºPowerPaint Inpainteræ¨¡å—

```python
# watermark_remover_ai/core/models/powerpaint_inpainter.py
"""
PowerPaint v2 + Realistic Vision V1.4-inpainting å›¾åƒä¿®å¤æ¨¡åž‹
"""

from typing import Any, Dict, Optional, Union
from PIL import Image
import numpy as np
import cv2
import logging
import torch
from pathlib import Path

from .base_model import BaseModel

logger = logging.getLogger(__name__)


class PowerPaintInpainter(BaseModel):
    """PowerPaint v2 å›¾åƒä¿®å¤æ¨¡åž‹"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–PowerPaintä¿®å¤å™¨
        
        Args:
            config: åŒ…å«powerpainté…ç½®çš„å­—å…¸
        """
        super().__init__(config)
        self.pipe = None
        self._load_model()
    
    def _load_model(self) -> None:
        """åŠ è½½PowerPaintæ¨¡åž‹"""
        try:
            from diffusers import StableDiffusionInpaintPipeline
            
            # èŽ·å–æ¨¡åž‹è·¯å¾„
            model_path = self.config.get('models', {}).get('powerpaint_model_path', 
                './models/powerpaint_v2/Realistic_Vision_V1.4-inpainting')
            
            # æ£€æŸ¥æ¨¡åž‹è·¯å¾„
            if not Path(model_path).exists():
                raise FileNotFoundError(f"PowerPaintæ¨¡åž‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            
            # åŠ è½½é…ç½®
            powerpaint_config = self.config.get('powerpaint_config', {})
            use_fp16 = powerpaint_config.get('use_fp16', True)
            enable_attention_slicing = powerpaint_config.get('enable_attention_slicing', True)
            
            # åŠ è½½æ¨¡åž‹
            logger.info(f"æ­£åœ¨åŠ è½½PowerPaintæ¨¡åž‹: {model_path}")
            self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
                model_path,
                torch_dtype=torch.float16 if use_fp16 else torch.float32,
                use_safetensors=True
            )
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            self.pipe = self.pipe.to(self.device)
            
            # å¯ç”¨å†…å­˜ä¼˜åŒ–
            if enable_attention_slicing:
                self.pipe.enable_attention_slicing()
            
            logger.info(f"âœ… PowerPaintæ¨¡åž‹åŠ è½½æˆåŠŸ: {model_path}")
            logger.info(f"   è®¾å¤‡: {self.device}")
            logger.info(f"   ç²¾åº¦: {self.pipe.unet.dtype}")
            
        except Exception as e:
            logger.error(f"PowerPaintæ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict(self, 
                image: Union[Image.Image, np.ndarray], 
                mask: Union[Image.Image, np.ndarray],
                custom_config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """
        æ‰§è¡Œå›¾åƒä¿®å¤
        
        Args:
            image: è¾“å…¥å›¾åƒ (PIL Image)
            mask: æŽ©ç å›¾åƒ (PIL Image)
            custom_config: è‡ªå®šä¹‰é…ç½®
            
        Returns:
            ä¿®å¤åŽçš„å›¾åƒæ•°ç»„ (RGBæ ¼å¼)
        """
        try:
            # é»˜è®¤é…ç½®
            default_config = {
                'num_inference_steps': 50,
                'guidance_scale': 7.5,
                'negative_prompt': 'watermark, logo, text, signature, blurry, low quality',
                'prompt': 'high quality, detailed, clean',
                'seed': -1
            }
            
            # åˆå¹¶è‡ªå®šä¹‰é…ç½®
            if custom_config:
                default_config.update(custom_config)
                logger.info(f"ðŸ“‹ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®: {custom_config}")
            
            # è®¾ç½®éšæœºç§å­
            if default_config['seed'] >= 0:
                torch.manual_seed(default_config['seed'])
                logger.info(f"ðŸŽ² ä½¿ç”¨å›ºå®šç§å­: {default_config['seed']}")
            
            # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
            if isinstance(image, np.ndarray):
                image = Image.fromarray(image)
            if isinstance(mask, np.ndarray):
                mask = Image.fromarray(mask)
            
            # ç¡®ä¿maskæ˜¯äºŒå€¼çš„
            mask_np = np.array(mask.convert('L'))
            mask_np = (mask_np > 128).astype(np.uint8) * 255
            mask = Image.fromarray(mask_np)
            
            logger.info(f"ðŸ–¼ï¸ è¾“å…¥å›¾åƒ: {image.size}, æ¨¡å¼: {image.mode}")
            logger.info(f"ðŸŽ­ è¾“å…¥mask: {mask.size}, è¦†ç›–çŽ‡: {np.sum(mask_np > 0) / mask_np.size * 100:.2f}%")
            
            # PowerPaintæŽ¨ç†
            logger.info("ðŸ¤– PowerPaintæ¨¡åž‹æŽ¨ç†...")
            result = self.pipe(
                prompt=default_config['prompt'],
                negative_prompt=default_config['negative_prompt'],
                image=image,
                mask_image=mask,
                num_inference_steps=default_config['num_inference_steps'],
                guidance_scale=default_config['guidance_scale'],
                generator=torch.Generator(device=self.device).manual_seed(default_config['seed']) if default_config['seed'] >= 0 else None
            ).images[0]
            
            logger.info("âœ… PowerPaintæŽ¨ç†å®Œæˆ!")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            result_np = np.array(result)
            logger.info(f"   è¾“å‡ºå›¾åƒ: shape={result_np.shape}, dtype={result_np.dtype}")
            
            return result_np
            
        except Exception as e:
            logger.error(f"PowerPaintä¿®å¤å¤±è´¥: {e}")
            raise
    
    def inpaint_image(self, 
                     image: Union[Image.Image, np.ndarray], 
                     mask: Union[Image.Image, np.ndarray],
                     custom_config: Optional[Dict[str, Any]] = None) -> Image.Image:
        """
        ä¿®å¤å›¾åƒå¹¶è¿”å›žPILå›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            mask: æŽ©ç å›¾åƒ
            custom_config: è‡ªå®šä¹‰é…ç½®
            
        Returns:
            ä¿®å¤åŽçš„PILå›¾åƒ
        """
        result_np = self.predict(image, mask, custom_config)
        return Image.fromarray(result_np)
    
    def get_model_info(self) -> Dict[str, Any]:
        """èŽ·å–æ¨¡åž‹ä¿¡æ¯"""
        info = super().get_model_info()
        info.update({
            "model_type": "PowerPaint_v2_RealisticVision",
            "base_model": "Realistic_Vision_V1.4-inpainting",
            "framework": "diffusers",
            "supports_fp16": True,
            "supports_attention_slicing": True
        })
        return info
```

### 2. æ›´æ–°é…ç½®æ–‡ä»¶

```yaml
# data/configs/web_config_powerpaint.yaml
# PowerPaint v2 ä¸“ç”¨é…ç½®

app:
  title: "AI Watermark Remover (PowerPaint v2)"
  host: "0.0.0.0"
  port: 8501
  debug: false

# å¤„ç†é€‰é¡¹
processing:
  default_max_bbox_percent: 10.0
  default_transparent: false
  default_overwrite: false
  default_force_format: "PNG"
  supported_formats: ["jpg", "jpeg", "png", "webp"]

# Maskç”Ÿæˆå™¨é…ç½®
mask_generator:
  model_type: "custom"  # "custom" or "florence"
  mask_model_path: "./models/epoch=071-valid_iou=0.7267.ckpt"
  image_size: 768
  imagenet_mean: [0.485, 0.456, 0.406]
  imagenet_std: [0.229, 0.224, 0.225]
  mask_threshold: 0.5
  mask_dilate_kernel_size: 3

# æ¨¡åž‹é…ç½®
models:
  florence_model: "microsoft/Florence-2-large"
  lama_model: "lama"  # ä¿ç•™LaMAä½œä¸ºå¤‡é€‰
  powerpaint_model_path: "./models/powerpaint_v2/Realistic_Vision_V1.4-inpainting"
  default_inpainting: "powerpaint"  # é»˜è®¤ä½¿ç”¨PowerPaint

# PowerPaintä¸“ç”¨é…ç½®
powerpaint_config:
  # åŸºç¡€å‚æ•°
  num_inference_steps: 50  # 10-200, æŽ¨ç†æ­¥æ•°
  guidance_scale: 7.5  # 1.0-20.0, å¼•å¯¼å°ºåº¦
  negative_prompt: "watermark, logo, text, signature, blurry, low quality, artifacts"
  prompt: "high quality, detailed, clean, professional"
  
  # æ€§èƒ½ä¼˜åŒ–
  use_fp16: true  # ä½¿ç”¨åŠç²¾åº¦
  enable_attention_slicing: true  # å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡
  enable_memory_efficient_attention: true  # å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›
  
  # é«˜çº§å‚æ•°
  seed: -1  # -1ä¸ºéšæœº, >=0ä¸ºå›ºå®šç§å­
  eta: 0.0  # 0.0-1.0, å™ªå£°è°ƒåº¦å™¨å‚æ•°
  
  # å›¾åƒé¢„å¤„ç†
  resize_to_512: true  # æ˜¯å¦è°ƒæ•´åˆ°512x512
  crop_strategy: "center"  # center, random, none
  
  # åŽå¤„ç†
  enable_face_restoration: false  # æ˜¯å¦å¯ç”¨é¢éƒ¨ä¿®å¤
  enable_color_correction: true  # æ˜¯å¦å¯ç”¨é¢œè‰²æ ¡æ­£

# æ–‡ä»¶å¤„ç†
files:
  max_upload_size: 20  # MB
  temp_dir: "./temp"
  output_dir: "./output"
  allowed_extensions: [".jpg", ".jpeg", ".png", ".webp"]

# UIè®¾ç½®
ui:
  show_advanced_options: true
  show_system_info: true
  enable_batch_processing: true
  default_download_format: "png"
  
  # PowerPaintä¸“ç”¨UIé€‰é¡¹
  show_powerpaint_params: true
  show_prompt_editor: true
  show_seed_control: true
```

### 3. æ›´æ–°æŽ¨ç†ç®¡ç†å™¨

```python
# inference.py ä¸­æ·»åŠ PowerPaintæ”¯æŒ
class EnhancedWatermarkProcessor:
    def __init__(self, base_processor):
        self.base_processor = base_processor
        self.powerpaint_inpainter = None
        self._load_powerpaint_model()
    
    def _load_powerpaint_model(self):
        """åŠ è½½PowerPaintæ¨¡åž‹"""
        try:
            from watermark_remover_ai.core.models.powerpaint_inpainter import PowerPaintInpainter
            self.powerpaint_inpainter = PowerPaintInpainter(self.base_processor.config)
            logger.info("PowerPaintæ¨¡åž‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.warning(f"PowerPaintæ¨¡åž‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨LaMA: {e}")
    
    def process_image_with_powerpaint(self, image, mask, inpaint_params):
        """ä½¿ç”¨PowerPaintå¤„ç†å›¾åƒ"""
        if self.powerpaint_inpainter is None:
            logger.warning("PowerPaintæ¨¡åž‹æœªåŠ è½½ï¼Œå›žé€€åˆ°LaMA")
            return self.base_processor._process_with_lama(image, mask, inpaint_params)
        
        # è½¬æ¢PowerPaintå‚æ•°
        powerpaint_config = {
            'num_inference_steps': inpaint_params.get('num_inference_steps', 50),
            'guidance_scale': inpaint_params.get('guidance_scale', 7.5),
            'negative_prompt': inpaint_params.get('negative_prompt', 'watermark, logo, text'),
            'prompt': inpaint_params.get('prompt', 'high quality, clean'),
            'seed': inpaint_params.get('seed', -1)
        }
        
        return self.powerpaint_inpainter.inpaint_image(image, mask, powerpaint_config)
```

### 4. æ›´æ–°UIç•Œé¢

```python
# ui.py ä¸­æ·»åŠ PowerPaintå‚æ•°æŽ§åˆ¶
class ParameterPanel:
    def _render_powerpaint_section(self) -> Dict[str, Any]:
        """æ¸²æŸ“PowerPaintå‚æ•°é¢æ¿"""
        st.sidebar.subheader("ðŸŽ¨ PowerPaint v2 å‚æ•°")
        
        # åŸºç¡€å‚æ•°
        num_inference_steps = st.slider(
            "æŽ¨ç†æ­¥æ•°", 10, 200, 50, 5,
            help="æ›´é«˜çš„æ­¥æ•° = æ›´å¥½çš„è´¨é‡ï¼Œä½†æ›´æ…¢"
        )
        
        guidance_scale = st.slider(
            "å¼•å¯¼å°ºåº¦", 1.0, 20.0, 7.5, 0.5,
            help="æŽ§åˆ¶ç”Ÿæˆå›¾åƒçš„åˆ›é€ æ€§ vs å‡†ç¡®æ€§"
        )
        
        # æç¤ºè¯ç¼–è¾‘
        st.sidebar.subheader("ðŸ“ æç¤ºè¯")
        prompt = st.text_area(
            "æ­£å‘æç¤ºè¯", 
            "high quality, detailed, clean, professional",
            help="æè¿°æœŸæœ›çš„å›¾åƒè´¨é‡"
        )
        
        negative_prompt = st.text_area(
            "è´Ÿå‘æç¤ºè¯",
            "watermark, logo, text, signature, blurry, low quality, artifacts",
            help="é¿å…çš„ç‰¹å¾"
        )
        
        # éšæœºç§å­
        seed = st.number_input(
            "éšæœºç§å­", -1, 999999, -1,
            help="-1ä¸ºéšæœºï¼Œ>=0ä¸ºå›ºå®šç§å­"
        )
        
        # æ€§èƒ½é€‰é¡¹
        st.sidebar.subheader("âš¡ æ€§èƒ½é€‰é¡¹")
        use_fp16 = st.checkbox("ä½¿ç”¨FP16", True, help="å‡å°‘æ˜¾å­˜å ç”¨ï¼Œæå‡é€Ÿåº¦")
        enable_attention_slicing = st.checkbox("æ³¨æ„åŠ›åˆ‡ç‰‡", True, help="å‡å°‘æ˜¾å­˜å ç”¨")
        
        return {
            'num_inference_steps': num_inference_steps,
            'guidance_scale': guidance_scale,
            'prompt': prompt,
            'negative_prompt': negative_prompt,
            'seed': seed,
            'use_fp16': use_fp16,
            'enable_attention_slicing': enable_attention_slicing
        }
```

## ðŸ§ª **æµ‹è¯•éªŒè¯**

### 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•

```bash
# åˆ›å»ºæµ‹è¯•è„šæœ¬
cat > test_powerpaint.py << 'EOF'
#!/usr/bin/env python3
"""
PowerPaint v2 åŠŸèƒ½æµ‹è¯•
"""

import torch
import numpy as np
from PIL import Image
from pathlib import Path
from watermark_remover_ai.core.models.powerpaint_inpainter import PowerPaintInpainter

def test_powerpaint_loading():
    """æµ‹è¯•æ¨¡åž‹åŠ è½½"""
    print("ðŸ§ª æµ‹è¯•PowerPaintæ¨¡åž‹åŠ è½½...")
    
    config = {
        'models': {
            'powerpaint_model_path': './models/powerpaint_v2/Realistic_Vision_V1.4-inpainting'
        },
        'powerpaint_config': {
            'use_fp16': True,
            'enable_attention_slicing': True
        }
    }
    
    try:
        inpainter = PowerPaintInpainter(config)
        print("âœ… PowerPaintæ¨¡åž‹åŠ è½½æˆåŠŸ!")
        print(f"   æ¨¡åž‹ä¿¡æ¯: {inpainter.get_model_info()}")
        return inpainter
    except Exception as e:
        print(f"âŒ PowerPaintæ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
        return None

def test_powerpaint_inference(inpainter):
    """æµ‹è¯•æŽ¨ç†åŠŸèƒ½"""
    print("\nðŸ§ª æµ‹è¯•PowerPaintæŽ¨ç†...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒå’Œmask
    test_image = Image.new('RGB', (512, 512), color='white')
    test_mask = Image.new('L', (512, 512), color=0)
    
    # åœ¨ä¸­å¿ƒåŒºåŸŸåˆ›å»ºmask
    mask_array = np.array(test_mask)
    mask_array[200:300, 200:300] = 255
    test_mask = Image.fromarray(mask_array)
    
    # æµ‹è¯•æŽ¨ç†
    try:
        result = inpainter.inpaint_image(
            test_image, 
            test_mask,
            {
                'num_inference_steps': 20,  # å¿«é€Ÿæµ‹è¯•
                'guidance_scale': 7.5,
                'prompt': 'high quality, clean',
                'negative_prompt': 'watermark, text',
                'seed': 42
            }
        )
        
        print("âœ… PowerPaintæŽ¨ç†æˆåŠŸ!")
        print(f"   è¾“å‡ºå›¾åƒå°ºå¯¸: {result.size}")
        
        # ä¿å­˜ç»“æžœ
        result.save('test_powerpaint_result.png')
        print("   ç»“æžœå·²ä¿å­˜åˆ°: test_powerpaint_result.png")
        
        return True
    except Exception as e:
        print(f"âŒ PowerPaintæŽ¨ç†å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # æµ‹è¯•æ¨¡åž‹åŠ è½½
    inpainter = test_powerpaint_loading()
    
    if inpainter:
        # æµ‹è¯•æŽ¨ç†
        test_powerpaint_inference(inpainter)
    
    print("\nðŸŽ‰ PowerPaint v2 æµ‹è¯•å®Œæˆ!")
EOF

# è¿è¡Œæµ‹è¯•
python test_powerpaint.py
```

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# åˆ›å»ºæ€§èƒ½æµ‹è¯•è„šæœ¬
cat > benchmark_powerpaint.py << 'EOF'
#!/usr/bin/env python3
"""
PowerPaint v2 æ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import time
import torch
import psutil
from PIL import Image
import numpy as np
from watermark_remover_ai.core.models.powerpaint_inpainter import PowerPaintInpainter

def benchmark_powerpaint():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("ðŸš€ PowerPaint v2 æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*50)
    
    # é…ç½®
    config = {
        'models': {
            'powerpaint_model_path': './models/powerpaint_v2/Realistic_Vision_V1.4-inpainting'
        },
        'powerpaint_config': {
            'use_fp16': True,
            'enable_attention_slicing': True
        }
    }
    
    # åŠ è½½æ¨¡åž‹
    print("ðŸ“¦ åŠ è½½PowerPaintæ¨¡åž‹...")
    start_time = time.time()
    inpainter = PowerPaintInpainter(config)
    load_time = time.time() - start_time
    print(f"   åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = Image.new('RGB', (512, 512), color='white')
    test_mask = Image.new('L', (512, 512), color=0)
    mask_array = np.array(test_mask)
    mask_array[200:300, 200:300] = 255
    test_mask = Image.fromarray(mask_array)
    
    # æµ‹è¯•ä¸åŒå‚æ•°çš„æ€§èƒ½
    test_configs = [
        {'num_inference_steps': 20, 'name': 'å¿«é€Ÿæ¨¡å¼'},
        {'num_inference_steps': 50, 'name': 'æ ‡å‡†æ¨¡å¼'},
        {'num_inference_steps': 100, 'name': 'é«˜è´¨é‡æ¨¡å¼'}
    ]
    
    for test_config in test_configs:
        print(f"\nðŸ” æµ‹è¯• {test_config['name']}...")
        
        # è®°å½•å¼€å§‹çŠ¶æ€
        start_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
        start_time = time.time()
        
        # æ‰§è¡ŒæŽ¨ç†
        result = inpainter.inpaint_image(
            test_image,
            test_mask,
            {
                'num_inference_steps': test_config['num_inference_steps'],
                'guidance_scale': 7.5,
                'prompt': 'high quality',
                'negative_prompt': 'watermark',
                'seed': 42
            }
        )
        
        # è®°å½•ç»“æŸçŠ¶æ€
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        inference_time = end_time - start_time
        memory_used = (end_memory - start_memory) / 1024**3  # GB
        
        print(f"   æŽ¨ç†æ—¶é—´: {inference_time:.2f}ç§’")
        print(f"   æ˜¾å­˜ä½¿ç”¨: {memory_used:.2f}GB")
        print(f"   å¤„ç†é€Ÿåº¦: {test_config['num_inference_steps']/inference_time:.1f}æ­¥/ç§’")
    
    print("\nâœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    benchmark_powerpaint()
EOF

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python benchmark_powerpaint.py
```

## ðŸš€ **å¯åŠ¨åº”ç”¨**

### 1. ä½¿ç”¨PowerPainté…ç½®å¯åŠ¨

```bash
# ä½¿ç”¨PowerPainté…ç½®å¯åŠ¨Web UI
python app.py web --config data/configs/web_config_powerpaint.yaml

# æˆ–è€…ä¿®æ”¹é»˜è®¤é…ç½®
cp data/configs/web_config_powerpaint.yaml data/configs/web_config.yaml
python app.py web
```

### 2. éªŒè¯åŠŸèƒ½

1. **è®¿é—®Webç•Œé¢**: http://localhost:8501
2. **ä¸Šä¼ æµ‹è¯•å›¾åƒ**
3. **é€‰æ‹©PowerPaint v2ä½œä¸ºinpaintingæ¨¡åž‹**
4. **è°ƒæ•´å‚æ•°å¹¶å¤„ç†**
5. **æ£€æŸ¥ç»“æžœè´¨é‡**

## ðŸ”§ **æ•…éšœæŽ’é™¤**

### å¸¸è§é—®é¢˜

#### 1. æ¨¡åž‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡åž‹è·¯å¾„
ls -la models/powerpaint_v2/Realistic_Vision_V1.4-inpainting/

# é‡æ–°ä¸‹è½½æ¨¡åž‹
rm -rf models/powerpaint_v2/Realistic_Vision_V1.4-inpainting/
git clone https://huggingface.co/Sanster/Realistic_Vision_V1.4-inpainting models/powerpaint_v2/Realistic_Vision_V1.4-inpainting
```

#### 2. æ˜¾å­˜ä¸è¶³
```python
# åœ¨é…ç½®ä¸­å¯ç”¨æ›´å¤šä¼˜åŒ–
powerpaint_config:
  use_fp16: true
  enable_attention_slicing: true
  enable_memory_efficient_attention: true
  enable_vae_slicing: true
```

#### 3. æŽ¨ç†é€Ÿåº¦æ…¢
```python
# è°ƒæ•´å‚æ•°
powerpaint_config:
  num_inference_steps: 30  # å‡å°‘æ­¥æ•°
  enable_attention_slicing: false  # å…³é—­æ³¨æ„åŠ›åˆ‡ç‰‡
```

## ðŸ“Š **æ€§èƒ½ä¼˜åŒ–å»ºè®®**

### 1. æ˜¾å­˜ä¼˜åŒ–
- å¯ç”¨FP16: `use_fp16: true`
- å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡: `enable_attention_slicing: true`
- å¯ç”¨VAEåˆ‡ç‰‡: `enable_vae_slicing: true`

### 2. é€Ÿåº¦ä¼˜åŒ–
- å‡å°‘æŽ¨ç†æ­¥æ•°: `num_inference_steps: 30-50`
- å…³é—­ä¸å¿…è¦çš„ä¼˜åŒ–é€‰é¡¹
- ä½¿ç”¨è¾ƒå°çš„è¾“å…¥å›¾åƒå°ºå¯¸

### 3. è´¨é‡ä¼˜åŒ–
- å¢žåŠ æŽ¨ç†æ­¥æ•°: `num_inference_steps: 50-100`
- è°ƒæ•´å¼•å¯¼å°ºåº¦: `guidance_scale: 7.5-10.0`
- ä¼˜åŒ–æç¤ºè¯

## ðŸŽ‰ **æ€»ç»“**

é€šè¿‡ä»¥ä¸Šæ­¥éª¤ï¼Œæ‚¨å·²æˆåŠŸï¼š

1. âœ… å®‰è£…äº†PowerPaint v2æ¡†æž¶
2. âœ… é›†æˆäº†Realistic Vision V1.4-inpaintingæ¨¡åž‹
3. âœ… é€‚é…äº†é¡¹ç›®æž¶æž„å’ŒUIè®¾è®¡
4. âœ… æ·»åŠ äº†å®Œæ•´çš„è°ƒè¯•å‚æ•°æŽ§åˆ¶
5. âœ… å®žçŽ°äº†æœ¬åœ°GPUæŽ¨ç†æ”¯æŒ

çŽ°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨PowerPaint v2 + Realistic Visionè¿›è¡Œé«˜è´¨é‡çš„æ°´å°åŽ»é™¤ä»»åŠ¡ï¼ŒåŒæ—¶ä¿æŒä¸ŽçŽ°æœ‰ç³»ç»Ÿçš„å®Œå…¨å…¼å®¹æ€§ï¼

## ðŸ”— **å‚è€ƒé“¾æŽ¥**

- [PowerPaint v2 å®˜æ–¹æ–‡æ¡£](https://www.iopaint.com/models/diffusion/powerpaint_v2)
- [Realistic Vision V1.4-inpainting æ¨¡åž‹](https://huggingface.co/Sanster/Realistic_Vision_V1.4-inpainting)
- [PowerPaint GitHub ä»“åº“](https://github.com/open-mmlab/PowerPaint) 