"""
Ê∞¥Âç∞Â§ÑÁêÜ‰∏ªÁ±ª - Ê®°ÂùóÂåñÁâàÊú¨
"""

import logging
import time
import yaml
import numpy as np
from typing import Dict, Any, Optional
from PIL import Image
from pathlib import Path

from .processing_result import ProcessingResult
from ..models.mask_generators import CustomMaskGenerator, FlorenceMaskGenerator, FallbackMaskGenerator
from ..models.lama_processor import LamaProcessor
from ..models.iopaint_processor import IOPaintProcessor

logger = logging.getLogger(__name__)

class WatermarkProcessor:
    """Ê∞¥Âç∞Â§ÑÁêÜ‰∏ªÁ±ª - Âü∫‰∫éÂéüÂßã web_backend.py"""
    
    def __init__(self, config_path: Optional[str] = None):
        if config_path is None:
            config_path = Path(__file__).parent.parent.parent / "web_config.yaml"
        self.config_path = config_path
        self.config = self._load_config(config_path)
        self._resources = []  # Track resources for cleanup
        
        # Initialize components
        self._init_components()
    
    def __enter__(self):
        """Context manager entry"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit with automatic cleanup"""
        self.cleanup_resources()
    
    def cleanup_resources(self):
        """Clean up all processor resources"""
        try:
            # Clean up LaMA processor
            if hasattr(self, 'lama_processor') and self.lama_processor:
                if hasattr(self.lama_processor, 'cleanup_resources'):
                    self.lama_processor.cleanup_resources()
            
            # Clean up mask generator if it has cleanup method
            if hasattr(self, 'mask_generator') and hasattr(self.mask_generator, 'cleanup_resources'):
                self.mask_generator.cleanup_resources()
            
            # Clear CUDA cache
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info("‚úÖ WatermarkProcessor resources cleaned up")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error during WatermarkProcessor cleanup: {e}")
    
    def _init_components(self):
        """Initialize processor components"""
        # ÂàùÂßãÂåñmaskÁîüÊàêÂô®
        mask_type = self.config['mask_generator']['model_type']
        try:
            if mask_type == "custom":
                self.mask_generator = CustomMaskGenerator(self.config)
            else:
                self.mask_generator = FlorenceMaskGenerator(self.config)
        except Exception as e:
            logger.error(f"Failed to initialize mask generator: {e}")
            # Êèê‰æõÈôçÁ∫ßÊñπÊ°à - ‰ΩøÁî®Âü∫Á°ÄÁöÑÁ©∫maskÁîüÊàêÂô®
            self.mask_generator = FallbackMaskGenerator()
            logger.info("Using fallback mask generator")
        
        # ÂàùÂßãÂåñLaMAÂ§ÑÁêÜÂô®
        try:
            self.lama_processor = LamaProcessor(self.config)
        except Exception as e:
            logger.error(f"Failed to initialize LaMA processor: {e}")
            raise RuntimeError(f"Critical failure: LaMA processor initialization failed: {e}")
        
        logger.info(f"‚úÖ WatermarkProcessor initialized with {mask_type} mask generator")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Âä†ËΩΩÈÖçÁΩÆÊñá‰ª∂"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                logger.info(f"‚úÖ Config loaded from: {config_path}")
                return config
        except Exception as e:
            logger.warning(f"Config file {config_path} not found, using defaults")
            # ‰ΩøÁî®ConfigManagerÁöÑÈªòËÆ§ÈÖçÁΩÆ
            from config.config import ConfigManager
            config_manager = ConfigManager()
            return self._build_default_config(config_manager)
    
    def _build_default_config(self, config_manager) -> Dict[str, Any]:
        """ÊûÑÂª∫ÈªòËÆ§ÈÖçÁΩÆ"""
        return {
            'mask_generator': {
                'model_type': 'custom',
                'mask_model_path': '/home/duolaameng/SAM_Remove/Watermark_sam/output/checkpoints/epoch=071-valid_iou=0.7267.ckpt',
                'image_size': 768,
                'imagenet_mean': [0.485, 0.456, 0.406],
                'imagenet_std': [0.229, 0.224, 0.225],
                'mask_threshold': config_manager.app_config.default_mask_threshold,
            },
            'models': {
                'florence_model': 'microsoft/Florence-2-large',
                'lama_model': config_manager.get_model_config().get('lama_model', 'lama')
            }
        }
    
    def process_image(self, 
                     image: Image.Image,
                     transparent: bool = False,
                     max_bbox_percent: float = 10.0,
                     force_format: Optional[str] = None,
                     custom_inpaint_config: Optional[Dict[str, Any]] = None) -> ProcessingResult:
        """Â§ÑÁêÜÂçïÂº†ÂõæÁâá"""
        start_time = time.time()
        
        try:
            logger.info("üöÄ ÂºÄÂßãÂ§ÑÁêÜÂõæÂÉè...")
            logger.info(f"üì∏ ËæìÂÖ•ÂõæÂÉè: size={image.size}, mode={image.mode}")
            logger.info(f"üéØ Â§ÑÁêÜÊ®°Âºè: {'ÈÄèÊòé' if transparent else '‰øÆÂ§ç'}")
            
            # ÁîüÊàêmask
            logger.info("üé≠ ÂºÄÂßãÁîüÊàêmask...")
            mask_params = {'max_bbox_percent': max_bbox_percent}
            mask_image = self.mask_generator.generate_mask(image, mask_params)
            
            # È™åËØÅmask
            mask_array = np.array(mask_image)
            white_pixels = np.sum(mask_array > 128)
            total_pixels = mask_array.size
            mask_coverage = white_pixels / total_pixels * 100
            logger.info(f"üîç MaskÈ™åËØÅ: Ë¶ÜÁõñÁéá={mask_coverage:.2f}%")
            
            if transparent:
                logger.info("ü´• Â∫îÁî®ÈÄèÊòéÂ§ÑÁêÜ...")
                result_image = self._make_region_transparent(image, mask_image)
            else:
                logger.info("üé® Â∫îÁî®LaMA‰øÆÂ§çÂ§ÑÁêÜ...")
                if custom_inpaint_config is None:
                    custom_inpaint_config = {}
                result_image_array = self.lama_processor.predict(image, mask_image, custom_inpaint_config)
                result_image = Image.fromarray(result_image_array)
            
            processing_time = time.time() - start_time
            logger.info(f"‚úÖ Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: {processing_time:.2f}Áßí")
            
            return ProcessingResult(
                success=True,
                result_image=result_image,
                mask_image=mask_image,
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"‚ùå ÂõæÂÉèÂ§ÑÁêÜÂ§±Ë¥•: {e}")
            return ProcessingResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time
            )
    
    def _make_region_transparent(self, image: Image.Image, mask: Image.Image) -> Image.Image:
        """‰ΩøÂå∫ÂüüÈÄèÊòé"""
        image = image.convert("RGBA")
        mask = mask.convert("L")
        transparent_image = Image.new("RGBA", image.size)
        
        for x in range(image.width):
            for y in range(image.height):
                if mask.getpixel((x, y)) > 0:
                    transparent_image.putpixel((x, y), (0, 0, 0, 0))
                else:
                    transparent_image.putpixel((x, y), image.getpixel((x, y)))
        
        return transparent_image
    
    def _process_with_lama(self, image: Image.Image, mask: Image.Image, lama_config: Dict[str, Any]) -> Image.Image:
        """‰ΩøÁî®LaMAËøõË°åinpainting - ÂÖºÂÆπÊé•Âè£"""
        result_array = self.lama_processor.predict(image, mask, lama_config)
        return Image.fromarray(result_array)
    
    def get_system_info(self) -> Dict[str, Any]:
        """Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ"""
        import torch
        import psutil
        
        info = {
            "cuda_available": torch.cuda.is_available(),
            "lama_loaded": self.lama_processor.model_loaded,
            "mask_generator": self.config['mask_generator']['model_type'],
            "ram_usage": f"{psutil.virtual_memory().percent:.1f}%",
            "cpu_usage": f"{psutil.cpu_percent():.1f}%"
        }
        
        if torch.cuda.is_available():
            gpu_info = torch.cuda.get_device_properties(0)
            vram_total = gpu_info.total_memory // (1024 ** 2)
            vram_used = torch.cuda.memory_reserved(0) // (1024 ** 2)
            info["vram_usage"] = f"{vram_used}/{vram_total} MB"
            info["gpu_name"] = gpu_info.name
        
        return info

class EnhancedWatermarkProcessor:
    """Â¢ûÂº∫ÁöÑÊ∞¥Âç∞Â§ÑÁêÜÂô® - ÊîØÊåÅ IOPaint"""
    
    def __init__(self, base_processor: WatermarkProcessor):
        self.base_processor = base_processor
        self.iopaint_processor = None
        self._load_iopaint_processor()
    
    def _load_iopaint_processor(self):
        """Load IOPaint processor"""
        try:
            # Create IOPaint config
            config = {
                'models': {
                    'inpaint_model': 'mat',  # ÈªòËÆ§‰ΩøÁî®MAT
                    'available_models': ['zits', 'mat', 'fcf', 'lama']
                },
                'iopaint_config': {
                    'hd_strategy': 'CROP',
                    'hd_strategy_crop_margin': 64,
                    'hd_strategy_crop_trigger_size': 1024,
                    'hd_strategy_resize_limit': 2048,
                    'ldm_steps': 50,
                    'auto_model_selection': True
                }
            }
            
            self.iopaint_processor = IOPaintProcessor(config)
            logger.info("‚úÖ IOPaint processor loaded successfully")
            
        except Exception as e:
            logger.warning(f"IOPaint processor loading failed: {e}")
            logger.info("IOPaint functionality will not be available")
    
    def process_image_with_params(self, 
                                image: Image.Image,
                                mask_model: str,
                                mask_params: Dict[str, Any],
                                inpaint_params: Dict[str, Any],
                                performance_params: Dict[str, Any],
                                transparent: bool = False) -> ProcessingResult:
        """‰ΩøÁî®ËØ¶ÁªÜÂèÇÊï∞Â§ÑÁêÜÂõæÂÉè"""
        start_time = time.time()
        
        try:
            logger.info("üöÄ ÂºÄÂßãÂ¢ûÂº∫Â§ÑÁêÜÊµÅÁ®ã...")
            logger.info(f"üé≠ MaskÊ®°Âûã: {mask_model}")
            logger.info(f"‚öôÔ∏è InpaintÂèÇÊï∞: {inpaint_params}")
            
            # ÁîüÊàêmask
            if mask_model == "upload":
                mask_image = self._generate_uploaded_mask(image, mask_params)
            elif mask_model == "florence2":
                mask_image = self.base_processor.mask_generator.generate_mask(image, mask_params)
            else:  # custom
                mask_image = self.base_processor.mask_generator.generate_mask(image, mask_params)
            
            # È™åËØÅmask
            mask_array = np.array(mask_image)
            white_pixels = np.sum(mask_array > 128)
            total_pixels = mask_array.size
            mask_coverage = white_pixels / total_pixels * 100
            logger.info(f"üîç MaskÈ™åËØÅ: Ë¶ÜÁõñÁéá={mask_coverage:.2f}%")
            
            # Â∫îÁî®Â§ÑÁêÜ
            if transparent:
                logger.info("ü´• Â∫îÁî®ÈÄèÊòéÂ§ÑÁêÜ...")
                result_image = self.base_processor._make_region_transparent(image, mask_image)
            else:
                inpaint_model = inpaint_params.get('inpaint_model', 'lama')
                
                if inpaint_model == 'iopaint' and self.iopaint_processor and self.iopaint_processor.model_loaded:
                    logger.info("üé® Â∫îÁî®IOPaintÂ§ÑÁêÜ...")
                    result_array = self.iopaint_processor.predict(image, mask_image, inpaint_params)
                    result_image = Image.fromarray(result_array)
                else:
                    logger.info("üé® Â∫îÁî®LaMAÂ§ÑÁêÜ...")
                    result_array = self.base_processor.lama_processor.predict(image, mask_image, inpaint_params)
                    result_image = Image.fromarray(result_array)
            
            processing_time = time.time() - start_time
            logger.info(f"‚úÖ Â§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: {processing_time:.2f}Áßí")
            
            return ProcessingResult(
                success=True,
                result_image=result_image,
                mask_image=mask_image,
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"‚ùå Â¢ûÂº∫Â§ÑÁêÜÂ§±Ë¥•: {e}")
            return ProcessingResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time
            )
    
    def _generate_uploaded_mask(self, image: Image.Image, params: Dict[str, Any]) -> Image.Image:
        """Â§ÑÁêÜ‰∏ä‰º†ÁöÑmask"""
        uploaded_mask = params.get('uploaded_mask')
        if not uploaded_mask:
            raise ValueError("No mask file uploaded")
        
        # Validate uploaded mask
        if hasattr(uploaded_mask, 'size') and uploaded_mask.size == 0:
            raise ValueError("Uploaded mask file is empty")
        
        try:
            logger.info(f"üìÇ Â§ÑÁêÜ‰∏ä‰º†ÁöÑmaskÊñá‰ª∂")
            logger.info(f"üìè ÂéüÂõæÂ∞∫ÂØ∏: {image.size}")
            
            # ËØªÂèñ‰∏ä‰º†ÁöÑmask
            if hasattr(uploaded_mask, 'read'):
                # Streamlit UploadedFileÂØπË±°
                uploaded_mask.seek(0)  # ÈáçÁΩÆÊñá‰ª∂ÊåáÈíà
                mask = Image.open(uploaded_mask)
            elif isinstance(uploaded_mask, Image.Image):
                # Â∑≤ÁªèÊòØPIL ImageÂØπË±°
                mask = uploaded_mask
            else:
                # Êñá‰ª∂Ë∑ØÂæÑ
                mask = Image.open(uploaded_mask)
                
        except Exception as e:
            raise ValueError(f"Failed to open uploaded mask file: {e}")
        
        # Validate mask after loading
        if mask.size[0] <= 0 or mask.size[1] <= 0:
            raise ValueError("Invalid mask dimensions")
        
        logger.info(f"üìè ÂéüÂßãmaskÂ∞∫ÂØ∏: {mask.size}")
        logger.info(f"üé® ÂéüÂßãmaskÊ®°Âºè: {mask.mode}")
        
        # Á°Æ‰øùmaskÊòØÁÅ∞Â∫¶ÂõæÂÉè
        if mask.mode != 'L':
            mask = mask.convert('L')
            logger.info(f"üîÑ ËΩ¨Êç¢mask‰∏∫ÁÅ∞Â∫¶Ê®°Âºè: {mask.mode}")
        
        # Ë∞ÉÊï¥maskÂ∞∫ÂØ∏‰ª•ÂåπÈÖçÂõæÂÉè
        if mask.size != image.size:
            logger.info(f"üìê Ë∞ÉÊï¥maskÂ∞∫ÂØ∏: {mask.size} -> {image.size}")
            mask = mask.resize(image.size, Image.LANCZOS)
        else:
            logger.info(f"‚úÖ MaskÂ∞∫ÂØ∏Â∑≤ÂåπÈÖç: {mask.size}")
        
        # Ê£ÄÊü•maskÂÜÖÂÆπ
        mask_array = np.array(mask)
        white_pixels = np.sum(mask_array > 128)
        total_pixels = mask_array.size
        mask_coverage = white_pixels / total_pixels * 100
        logger.info(f"üîç MaskÂÜÖÂÆπÂàÜÊûê: ÁôΩËâ≤ÂÉèÁ¥†={white_pixels}, ÊÄªÂÉèÁ¥†={total_pixels}, Ë¶ÜÁõñÁéá={mask_coverage:.2f}%")
        logger.info(f"üìä MaskÂÉèÁ¥†ÂÄºËåÉÂõ¥: {mask_array.min()} - {mask_array.max()}")
        
        # Â∫îÁî®È¢ùÂ§ñÁöÑËÜ®ËÉÄÂ§ÑÁêÜÔºàÂ¶ÇÊûúÈúÄË¶ÅÔºâ
        dilate_size = params.get('mask_dilate_kernel_size', 0)
        if dilate_size > 0:
            import cv2
            logger.info(f"üîß Â∫îÁî®ËÜ®ËÉÄÂ§ÑÁêÜ: kernel_size={dilate_size}")
            mask_array = np.array(mask)
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_size, dilate_size))
            mask_array = cv2.dilate(mask_array, kernel, iterations=1)
            mask = Image.fromarray(mask_array, mode='L')
            
            # Ê£ÄÊü•ËÜ®ËÉÄÂêéÁöÑmask
            white_pixels_after = np.sum(mask_array > 128)
            coverage_after = white_pixels_after / total_pixels * 100
            logger.info(f"üîç ËÜ®ËÉÄÂêéMaskÂàÜÊûê: ÁôΩËâ≤ÂÉèÁ¥†={white_pixels_after}, Ë¶ÜÁõñÁéá={coverage_after:.2f}%")
        
        logger.info(f"‚úÖ ÊúÄÁªàmaskÂ∞∫ÂØ∏: {mask.size}, Ê®°Âºè: {mask.mode}")
        return mask 