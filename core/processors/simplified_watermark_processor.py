"""
ç®€åŒ–æ°´å°å¤„ç†å™¨ - SIMP-LAMAæ¶æ„å®ç°
ç»Ÿä¸€å…¥å£ç‚¹ï¼Œæ”¯æŒMAT/ZITS/FCF/LaMAæ¨¡å‹é€‰æ‹©
éµå¾ªå•ä¸€å…¥å£ã€æ¥å£ç»Ÿä¸€ã€è‡ªåŠ¨èµ„æºç®¡ç†åŸåˆ™
"""

import logging
import time
import torch
import numpy as np
from typing import Dict, Any, Optional, Union
from PIL import Image
from pathlib import Path

from .processing_result import ProcessingResult
from ..models.unified_mask_generator import UnifiedMaskGenerator
from ..utils.memory_monitor import MemoryMonitor
from ..utils.image_utils import ImageUtils

logger = logging.getLogger(__name__)

class SimplifiedWatermarkProcessor:
    """
    ç®€åŒ–æ°´å°å¤„ç†å™¨ - SIMP-LAMAæ¶æ„
    
    æ ¸å¿ƒç‰¹æ€§:
    - Single Entry: ç»Ÿä¸€çš„process_imageæ¥å£
    - Interface Unification: æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€æ¥å£
    - Auto Resource: æ™ºèƒ½æ¨¡å‹åˆ‡æ¢å’Œå†…å­˜ç®¡ç†
    - Pluggable Models: æ”¯æŒMAT/ZITS/FCF/LaMAæ¨¡å‹
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.current_model = None
        self.current_model_name = None
        self.model_cache = {}  # æ¨¡å‹ç¼“å­˜ï¼Œå®ç°æ‡’åŠ è½½
        self.memory_monitor = MemoryMonitor()
        
        # åˆå§‹åŒ–maskç”Ÿæˆå™¨
        self._init_mask_generator()
        
        # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        self.available_models = ["mat", "zits", "fcf", "lama"]
        
        logger.info("âœ… SimplifiedWatermarkProcessor initialized")
        logger.info(f"   Available models: {self.available_models}")
        logger.info(f"   Memory management: enabled")
    
    def _init_mask_generator(self):
        """åˆå§‹åŒ–ç»Ÿä¸€maskç”Ÿæˆå™¨"""
        try:
            self.mask_generator = UnifiedMaskGenerator(self.config)
            logger.info("âœ… Unified mask generator initialized")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize mask generator: {e}")
            raise RuntimeError(f"Mask generator initialization failed: {e}")
    
    def process_image(self, 
                     image: Image.Image,
                     model_name: str = "mat",
                     mask_method: str = "custom",
                     config: Optional[Dict[str, Any]] = None) -> ProcessingResult:
        """
        ç»Ÿä¸€å…¥å£ç‚¹ - å¤„ç†å›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            model_name: æ¨¡å‹åç§° (mat/zits/fcf/lama)
            mask_method: maskç”Ÿæˆæ–¹æ³• (custom/upload)
            config: å¤„ç†é…ç½®
            
        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        start_time = time.time()
        
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†å›¾åƒ - æ¨¡å‹: {model_name}")
            logger.info(f"ğŸ“¸ è¾“å…¥å›¾åƒ: {image.size}, æ¨¡å¼: {image.mode}")
            
            # éªŒè¯æ¨¡å‹åç§°
            if model_name not in self.available_models:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. å¯ç”¨æ¨¡å‹: {self.available_models}")
            
            # 1. ç”Ÿæˆmask
            mask_image = self._generate_mask(image, mask_method, config)
            
            # 2. åˆ‡æ¢åˆ°æŒ‡å®šæ¨¡å‹
            self._switch_model(model_name)
            
            # 3. æ‰§è¡Œinpainting
            result_image = self._inpaint_image(image, mask_image, config)
            
            processing_time = time.time() - start_time
            logger.info(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return ProcessingResult(
                success=True,
                result_image=result_image,
                mask_image=mask_image,
                processing_time=processing_time,
                model_used=model_name,
                memory_info=self.memory_monitor.get_memory_info()
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}")
            
            return ProcessingResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time,
                model_used=model_name,
                memory_info=self.memory_monitor.get_memory_info()
            )
    
    def _generate_mask(self, image: Image.Image, method: str, config: Dict[str, Any]) -> Image.Image:
        """ç”Ÿæˆmask - SIMP-LAMAç»Ÿä¸€æ¥å£"""
        try:
            logger.info(f"ğŸ­ ç”Ÿæˆmask - æ–¹æ³•: {method}")
            
            # å‡†å¤‡å‚æ•°
            mask_params = config.get('mask_params', {})
            if method == "upload":
                mask_params['uploaded_mask'] = config.get('uploaded_mask')
            
            # ä½¿ç”¨ç»Ÿä¸€maskç”Ÿæˆå™¨
            mask_image = self.mask_generator.generate_mask(image, method, mask_params)
            
            # éªŒè¯maskå…¼å®¹æ€§
            if not self.mask_generator.validate_mask_compatibility(mask_image, self.current_model_name or "unknown"):
                logger.warning("âš ï¸ Maskå…¼å®¹æ€§æ£€æŸ¥æœªé€šè¿‡ï¼Œä½†ç»§ç»­å¤„ç†")
            
            # è·å–maskä¿¡æ¯
            mask_info = self.mask_generator.get_mask_info(mask_image)
            logger.info(f"ğŸ” Maskä¿¡æ¯: {mask_info['coverage_percent']:.2f}% è¦†ç›–ç‡, {mask_info['unique_values']} å”¯ä¸€å€¼")
            
            return mask_image
            
        except Exception as e:
            logger.error(f"âŒ Maskç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _switch_model(self, model_name: str):
        """æ™ºèƒ½æ¨¡å‹åˆ‡æ¢ - è‡ªåŠ¨å†…å­˜ç®¡ç†"""
        if self.current_model_name == model_name and self.current_model is not None:
            logger.info(f"âœ… æ¨¡å‹ {model_name} å·²åŠ è½½ï¼Œæ— éœ€åˆ‡æ¢")
            return
        
        try:
            # æ¸…ç†å½“å‰æ¨¡å‹
            if self.current_model is not None:
                logger.info(f"ğŸ”„ å¸è½½å½“å‰æ¨¡å‹: {self.current_model_name}")
                self._cleanup_current_model()
            
            # æ£€æŸ¥å†…å­˜çŠ¶æ€
            memory_info = self.memory_monitor.get_memory_info()
            logger.info(f"ğŸ“Š åˆ‡æ¢å‰å†…å­˜çŠ¶æ€: {memory_info}")
            
            # åŠ è½½æ–°æ¨¡å‹
            logger.info(f"â³ åŠ è½½æ¨¡å‹: {model_name}")
            self.current_model = self._load_model(model_name)
            self.current_model_name = model_name
            
            # æ£€æŸ¥åˆ‡æ¢åå†…å­˜çŠ¶æ€
            memory_info = self.memory_monitor.get_memory_info()
            logger.info(f"ğŸ“Š åˆ‡æ¢åå†…å­˜çŠ¶æ€: {memory_info}")
            logger.info(f"âœ… æ¨¡å‹åˆ‡æ¢å®Œæˆ: {model_name}")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥: {e}")
            self.current_model = None
            self.current_model_name = None
            raise
    
    def _load_model(self, model_name: str):
        """åŠ è½½æŒ‡å®šæ¨¡å‹ - ä½¿ç”¨æ¨¡å‹æ³¨å†Œè¡¨å®ç°æ‡’åŠ è½½"""
        try:
            # å¯¼å…¥æ¨¡å‹ä»¥ç¡®ä¿å®ƒä»¬è¢«æ³¨å†Œ
            from ..models.mat_processor import MatProcessor
            from ..models.zits_processor import ZitsProcessor  
            from ..models.fcf_processor import FcfProcessor
            # LaMAå¯èƒ½æœ‰ä¾èµ–é—®é¢˜ï¼Œå•ç‹¬å¤„ç†
            
            # å¯¼å…¥ç®€åŒ–LaMAå¤„ç†å™¨ä»¥ç¡®ä¿æ³¨å†Œ
            from ..models.lama_processor_simplified import SimplifiedLamaProcessor
            
            # ä½¿ç”¨æ¨¡å‹æ³¨å†Œè¡¨ç»Ÿä¸€åˆ›å»ºæ¨¡å‹
            from ..models.base_inpainter import ModelRegistry
            return ModelRegistry.create_model(model_name, self.config)
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _cleanup_current_model(self):
        """æ¸…ç†å½“å‰æ¨¡å‹èµ„æº"""
        try:
            if hasattr(self.current_model, 'cleanup_resources'):
                self.current_model.cleanup_resources()
            
            del self.current_model
            self.current_model = None
            
            # å¼ºåˆ¶æ¸…ç†CUDAç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.ipc_collect()
            
            logger.info("âœ… æ¨¡å‹èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ¨¡å‹æ¸…ç†æ—¶å‡ºç°é”™è¯¯: {e}")
    
    def _inpaint_image(self, image: Image.Image, mask: Image.Image, config: Dict[str, Any]) -> Image.Image:
        """ç»Ÿä¸€inpaintingæ¥å£"""
        if self.current_model is None:
            raise RuntimeError("å½“å‰æ²¡æœ‰åŠ è½½çš„æ¨¡å‹")
        
        try:
            # é¢„å¤„ç†å›¾åƒå’Œmask
            processed_image, processed_mask = ImageUtils.preprocess_for_model(
                image, mask, self.current_model_name
            )
            
            # æ‰§è¡Œinpainting
            logger.info(f"ğŸ¨ æ‰§è¡Œ{self.current_model_name.upper()}æ¨ç†...")
            inpaint_config = config.get('inpaint_params', {})
            
            # è°ƒç”¨æ¨¡å‹çš„ç»Ÿä¸€æ¥å£
            result_array = self.current_model.predict(processed_image, processed_mask, inpaint_config)
            
            # åå¤„ç†ç»“æœ
            result_image = ImageUtils.postprocess_result(
                result_array, self.current_model_name, image.size
            )
            
            return result_image
            
        except Exception as e:
            logger.error(f"âŒ {self.current_model_name}æ¨ç†å¤±è´¥: {e}")
            raise
    
    def get_model_status(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€ä¿¡æ¯"""
        memory_info = self.memory_monitor.get_memory_info()
        
        return {
            "current_model": self.current_model_name,
            "available_models": self.available_models,
            "model_loaded": self.current_model is not None,
            "memory_info": memory_info,
            "mask_generator_status": "ready" if self.mask_generator else "error"
        }
    
    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        try:
            logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†æ‰€æœ‰èµ„æº...")
            
            # æ¸…ç†å½“å‰æ¨¡å‹
            if self.current_model is not None:
                self._cleanup_current_model()
            
            # æ¸…ç†maskç”Ÿæˆå™¨
            if hasattr(self.mask_generator, 'cleanup_resources'):
                self.mask_generator.cleanup_resources()
            
            # æ¸…ç†æ¨¡å‹ç¼“å­˜
            self.model_cache.clear()
            
            logger.info("âœ… æ‰€æœ‰èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ èµ„æºæ¸…ç†æ—¶å‡ºç°é”™è¯¯: {e}")
    
    def __enter__(self):
        """Context manager entry"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit - è‡ªåŠ¨èµ„æºæ¸…ç†"""
        self.cleanup()

# å…¨å±€å®ä¾‹ç®¡ç†å™¨
class ProcessorManager:
    """å¤„ç†å™¨ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼"""
    
    _instance = None
    _processor = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def get_processor(self, config: Dict[str, Any]) -> SimplifiedWatermarkProcessor:
        """è·å–å¤„ç†å™¨å®ä¾‹"""
        if self._processor is None:
            self._processor = SimplifiedWatermarkProcessor(config)
        return self._processor
    
    def cleanup(self):
        """æ¸…ç†å¤„ç†å™¨"""
        if self._processor is not None:
            self._processor.cleanup()
            self._processor = None

# å…¨å±€ç®¡ç†å™¨å®ä¾‹
processor_manager = ProcessorManager()