"""
åŸºç¡€Inpaintingæ¨¡å‹æ¥å£
å®šä¹‰æ‰€æœ‰æ¨¡å‹å¿…é¡»å®ç°çš„ç»Ÿä¸€æ¥å£
"""

from abc import ABC, abstractmethod
import numpy as np
from typing import Dict, Any, Optional
from PIL import Image
import logging

logger = logging.getLogger(__name__)

class BaseInpainter(ABC):
    """
    åŸºç¡€Inpaintingæ¨¡å‹æŠ½è±¡ç±»
    æ‰€æœ‰IOPaintæ¨¡å‹éƒ½å¿…é¡»å®ç°è¿™ä¸ªæ¥å£
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model_loaded = False
        self.device = None
    
    @abstractmethod
    def _load_model(self):
        """åŠ è½½æ¨¡å‹ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @abstractmethod
    def predict(self, image: Image.Image, mask: Image.Image, config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """
        ç»Ÿä¸€çš„inpaintingæ¨ç†æ¥å£
        
        Args:
            image: è¾“å…¥å›¾åƒ (PIL.Image)
            mask: è¾“å…¥mask (PIL.Image, ç°åº¦å›¾)
            config: æ¨ç†é…ç½®å‚æ•°
            
        Returns:
            np.ndarray: å¤„ç†åçš„å›¾åƒæ•°ç»„ (RGBæ ¼å¼)
        """
        pass
    
    @abstractmethod
    def cleanup_resources(self):
        """æ¸…ç†æ¨¡å‹èµ„æº - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    def is_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return self.model_loaded
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_loaded': self.model_loaded,
            'device': str(self.device) if self.device else None,
            'config': self.config
        }
    
    def get_available_models(self) -> list:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ - é»˜è®¤å®ç°"""
        return [getattr(self, 'model_name', 'unknown')]
    
    def get_current_model(self) -> str:
        """è·å–å½“å‰æ¨¡å‹åç§° - é»˜è®¤å®ç°"""
        return getattr(self, 'model_name', 'unknown')
    
    def predict_with_model(self, image: Image.Image, mask: Image.Image, config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ - é»˜è®¤è°ƒç”¨predictæ–¹æ³•"""
        return self.predict(image, mask, config)
    
    def process_image(self, image: Image.Image, mask: Image.Image, config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """å¤„ç†å›¾åƒ - é»˜è®¤è°ƒç”¨predictæ–¹æ³•"""
        return self.predict(image, mask, config)
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹ - é»˜è®¤è°ƒç”¨_load_modelæ–¹æ³•"""
        return self._load_model()
    
    def validate_inputs(self, image: Image.Image, mask: Image.Image) -> bool:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        try:
            # æ£€æŸ¥å›¾åƒ
            if not isinstance(image, Image.Image):
                logger.error("Input image must be PIL.Image")
                return False
            
            if image.size[0] <= 0 or image.size[1] <= 0:
                logger.error("Invalid image size")
                return False
            
            # æ£€æŸ¥mask
            if not isinstance(mask, Image.Image):
                logger.error("Input mask must be PIL.Image")
                return False
                
            if mask.size != image.size:
                logger.error(f"Size mismatch: image {image.size}, mask {mask.size}")
                return False
            
            # æ£€æŸ¥maskæ ¼å¼
            if mask.mode != 'L':
                logger.warning(f"Mask mode {mask.mode} will be converted to 'L'")
            
            return True
            
        except Exception as e:
            logger.error(f"Input validation failed: {e}")
            return False
    
    def preprocess_inputs(self, image: Image.Image, mask: Image.Image) -> tuple:
        """é¢„å¤„ç†è¾“å…¥æ•°æ®"""
        # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # ç¡®ä¿maskæ˜¯ç°åº¦æ ¼å¼
        if mask.mode != 'L':
            mask = mask.convert('L')
        
        # ç¡®ä¿å°ºå¯¸åŒ¹é…
        if image.size != mask.size:
            mask = mask.resize(image.size, Image.NEAREST)
        
        return image, mask

class IOPaintBaseProcessor(BaseInpainter):
    """
    IOPaintæ¨¡å‹çš„åŸºç¡€å¤„ç†å™¨
    æä¾›é€šç”¨çš„IOPainté›†æˆåŠŸèƒ½
    """
    
    def __init__(self, config: Dict[str, Any], model_name: str):
        super().__init__(config)
        self.model_name = model_name
        self.model_manager = None
        self._load_iopaint_classes()
    
    def _load_iopaint_classes(self):
        """åŠ è½½IOPaintç›¸å…³ç±»"""
        try:
            from iopaint.model_manager import ModelManager
            from iopaint.schema import HDStrategy, LDMSampler, InpaintRequest as Config
            
            self.ModelManager = ModelManager
            self.HDStrategy = HDStrategy
            self.LDMSampler = LDMSampler
            self.Config = Config
            
        except ImportError as e:
            logger.error(f"Failed to import IOPaint classes: {e}")
            raise
    
    def _load_model(self):
        """åŠ è½½IOPaintæ¨¡å‹"""
        try:
            import torch
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # åŠ è½½æŒ‡å®šæ¨¡å‹
            self.model_manager = self.ModelManager(name=self.model_name, device=str(self.device))
            
            self.model_loaded = True
            logger.info(f"âœ… {self.model_name.upper()} model loaded successfully")
            logger.info(f"   Device: {self.device}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load {self.model_name} model: {e}")
            self.model_loaded = False
            raise
    
    def _build_iopaint_config(self, config: Dict[str, Any]) -> object:
        """æ„å»ºIOPainté…ç½®å¯¹è±¡"""
        # é»˜è®¤å‚æ•°
        default_config = {
            'ldm_steps': 50,
            'ldm_sampler': 'ddim',
            'hd_strategy': 'CROP',
            'hd_strategy_crop_margin': 64,
            'hd_strategy_crop_trigger_size': 1024,
            'hd_strategy_resize_limit': 2048
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        merged_config = {**default_config, **config}
        
        # æ˜ å°„ç­–ç•¥
        strategy_map = {
            'CROP': self.HDStrategy.CROP,
            'RESIZE': self.HDStrategy.RESIZE,
            'ORIGINAL': self.HDStrategy.ORIGINAL
        }
        
        # æ˜ å°„é‡‡æ ·å™¨ï¼ˆä»…æ”¯æŒIOPaintå®é™…å¯ç”¨çš„é‡‡æ ·å™¨ï¼‰
        sampler_map = {
            'ddim': self.LDMSampler.ddim,
            'plms': self.LDMSampler.plms
        }
        
        return self.Config(
            ldm_steps=merged_config['ldm_steps'],
            ldm_sampler=sampler_map.get(merged_config['ldm_sampler'], self.LDMSampler.ddim),
            hd_strategy=strategy_map.get(merged_config['hd_strategy'], self.HDStrategy.CROP),
            hd_strategy_crop_margin=merged_config['hd_strategy_crop_margin'],
            hd_strategy_crop_trigger_size=merged_config['hd_strategy_crop_trigger_size'],
            hd_strategy_resize_limit=merged_config['hd_strategy_resize_limit']
        )
    
    def predict(self, image: Image.Image, mask: Image.Image, config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """ç»Ÿä¸€çš„IOPaintæ¨ç†æ¥å£"""
        if not self.model_loaded:
            raise RuntimeError(f"{self.model_name} model not loaded")
        
        # éªŒè¯è¾“å…¥
        if not self.validate_inputs(image, mask):
            raise ValueError("Invalid inputs")
        
        # é¢„å¤„ç†
        image, mask = self.preprocess_inputs(image, mask)
        
        try:
            from ..utils.image_utils import ImageUtils
            
            # ä¸ºIOPaintå‡†å¤‡æ•°ç»„ï¼ˆæ ‡å‡†RGBå¤„ç†ï¼‰
            image_array, mask_array = ImageUtils.prepare_arrays_for_iopaint(image, mask)
            
            logger.info(f"ğŸ¨ {self.model_name.upper()} processing: {image_array.shape}")
            
            # æ„å»ºé…ç½®
            if config is None:
                config = {}
            iopaint_config = self._build_iopaint_config(config)
            
            # æ‰§è¡Œæ¨ç†
            result = self.model_manager(image_array, mask_array, iopaint_config)
            
            logger.info(f"âœ… {self.model_name.upper()} processing completed")
            return result
            
        except Exception as e:
            logger.error(f"{self.model_name} prediction failed: {e}")
            raise
    
    def cleanup_resources(self):
        """æ¸…ç†IOPaintèµ„æº"""
        try:
            if self.model_manager is not None:
                del self.model_manager
            self.model_manager = None
            self.model_loaded = False
            
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info(f"âœ… {self.model_name.upper()} processor resources cleaned up")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Error during {self.model_name} processor cleanup: {e}")

class ModelRegistry:
    """æ¨¡å‹æ³¨å†Œè¡¨ - ç®¡ç†æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ç±»"""
    
    _models = {}
    
    @classmethod
    def register(cls, name: str, model_class: type):
        """æ³¨å†Œæ¨¡å‹ç±»"""
        cls._models[name] = model_class
        logger.info(f"âœ… Model {name} registered")
    
    @classmethod
    def get_model_class(cls, name: str) -> type:
        """è·å–æ¨¡å‹ç±»"""
        if name not in cls._models:
            raise ValueError(f"Model {name} not registered")
        return cls._models[name]
    
    @classmethod
    def get_available_models(cls) -> list:
        """è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        return list(cls._models.keys())
    
    @classmethod
    def create_model(cls, name: str, config: Dict[str, Any]) -> BaseInpainter:
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        model_class = cls.get_model_class(name)
        return model_class(config)