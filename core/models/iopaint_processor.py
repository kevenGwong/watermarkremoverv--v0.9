"""
IOPaintç»Ÿä¸€å¤„ç†å™¨
æ”¯æŒZITSã€MATã€FCFã€LaMAç­‰å¤šç§æ¨¡å‹
ä¿®æ”¹ç‰ˆæœ¬ï¼šæŒ‰ç”¨æˆ·éœ€æ±‚æ”¯æŒZITSã€MATã€FCF + LaMA
"""

import numpy as np
from PIL import Image
from typing import Dict, Any, Optional, Union
import logging
from pathlib import Path

# å°è¯•å¯¼å…¥torchï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›é™çº§æ–¹æ¡ˆ
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ PyTorch not available, IOPaint functionality will be limited")

from .base_model import BaseModel

logger = logging.getLogger(__name__)

class IOPaintProcessor(BaseModel):
    """IOPaintç»Ÿä¸€å¤„ç†å™¨ï¼Œæ”¯æŒå¤šç§å…ˆè¿›æ¨¡å‹"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model_manager = None
        self.current_model = None
        self.available_models = ["zits", "mat", "fcf", "lama"]
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½IOPaintæ¨¡å‹"""
        try:
            from iopaint.model_manager import ModelManager
            from iopaint.schema import HDStrategy, LDMSampler, InpaintRequest as Config
            
            # è·å–æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨MAT
            model_name = self.config.get('models', {}).get('inpaint_model', 'mat')
            
            # ç¡®ä¿æ¨¡å‹åœ¨æ”¯æŒåˆ—è¡¨ä¸­
            if model_name not in self.available_models:
                logger.warning(f"ä¸æ”¯æŒçš„æ¨¡å‹ {model_name}ï¼Œä½¿ç”¨é»˜è®¤MAT")
                model_name = 'mat'
            
            self.model_manager = ModelManager(name=model_name, device=str(self.device))
            self.current_model = model_name
            self.register_model(self.model_manager)
            
            # å­˜å‚¨é…ç½®ç±»
            self.HDStrategy = HDStrategy
            self.LDMSampler = LDMSampler
            self.Config = Config
            
            self.model_loaded = True
            logger.info(f"âœ… IOPaintæ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            logger.info(f"   è®¾å¤‡: {self.device}")
            logger.info(f"   æ”¯æŒçš„æ¨¡å‹: {self.available_models}")
            
        except Exception as e:
            logger.error(f"âŒ IOPaintæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model_loaded = False
            raise
    
    def switch_model(self, model_name: str):
        """åŠ¨æ€åˆ‡æ¢æ¨¡å‹"""
        if model_name == self.current_model:
            return
            
        if model_name not in self.available_models:
            logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}ï¼Œæ”¯æŒçš„æ¨¡å‹: {self.available_models}")
            return
            
        try:
            from iopaint.model_manager import ModelManager
            
            # æ¸…ç†æ—§æ¨¡å‹
            if self.model_manager:
                del self.model_manager
                if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()  # æ¸…ç†GPUå†…å­˜
                
            # åŠ è½½æ–°æ¨¡å‹
            self.model_manager = ModelManager(name=model_name, device=str(self.device))
            self.current_model = model_name
            self.register_model(self.model_manager)
            
            logger.info(f"ğŸ”„ æ¨¡å‹åˆ‡æ¢æˆåŠŸ: {model_name}")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥: {e}")
            raise
    
    def predict(self, 
                image: Union[Image.Image, np.ndarray], 
                mask: Union[Image.Image, np.ndarray],
                custom_config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """æ‰§è¡ŒInpaintingé¢„æµ‹"""
        
        if not self.model_loaded:
            raise RuntimeError("IOPaintæ¨¡å‹æœªåŠ è½½")
        
        # éªŒè¯è¾“å…¥
        image, mask = self.validate_inputs(image, mask)
        
        # è·å–å¤„ç†å‚æ•°
        params = self._get_processing_params(custom_config)
        
        # æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if params.get('auto_model_selection', True):
            optimal_model = self._choose_optimal_model(image, mask, params)
            if optimal_model != self.current_model:
                self.switch_model(optimal_model)
        
        # æ‰‹åŠ¨æ¨¡å‹é€‰æ‹©ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if 'force_model' in params and params['force_model'] in self.available_models:
            if params['force_model'] != self.current_model:
                self.switch_model(params['force_model'])
        
        try:
            # å¤„ç†å›¾åƒæ ¼å¼
            if isinstance(image, Image.Image):
                image_rgb = np.array(image.convert("RGB"))
            else:
                image_rgb = image
                
            if isinstance(mask, Image.Image):
                mask_gray = np.array(mask.convert("L"))
            else:
                mask_gray = mask
            
            logger.info(f"ğŸ¨ ä½¿ç”¨{self.current_model}æ¨¡å‹å¤„ç†: {image_rgb.shape}")
            
            # æ„å»ºIOPainté…ç½®
            config = self._build_iopaint_config(params)
            
            # æ‰§è¡Œinpainting
            result = self.model_manager(image_rgb, mask_gray, config)
            
            logger.info(f"âœ… {self.current_model}å¤„ç†å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ {self.current_model}å¤„ç†å¤±è´¥: {e}")
            raise
    
    def _choose_optimal_model(self, image, mask, params) -> str:
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ¨¡å‹"""
        
        # è®¡ç®—maskè¦†ç›–ç‡
        if isinstance(mask, Image.Image):
            mask_array = np.array(mask.convert("L"))
        else:
            mask_array = mask
            
        mask_coverage = np.sum(mask_array > 128) / mask_array.size * 100
        
        # è·å–å›¾åƒå¤æ‚åº¦ï¼ˆè¾¹ç¼˜å¯†åº¦ï¼‰
        image_complexity = self._calculate_image_complexity(image)
        
        # æ™ºèƒ½é€‰æ‹©ç­–ç•¥ï¼ˆæ ¹æ®ç”¨æˆ·éœ€æ±‚è°ƒæ•´ï¼‰
        if mask_coverage > 30:
            return 'mat'      # å¤§æ°´å°ç”¨MATï¼ˆæœ€ä½³è´¨é‡ï¼‰
        elif image_complexity > 0.7:
            return 'zits'     # å¤æ‚ç»“æ„ç”¨ZITSï¼ˆæœ€ä½³ç»“æ„ä¿æŒï¼‰
        elif mask_coverage < 5:
            return 'lama'     # å°æ°´å°ç”¨LaMAï¼ˆæœ€å¿«é€Ÿåº¦ï¼‰
        else:
            return 'fcf'      # ä¸­ç­‰æƒ…å†µç”¨FCFï¼ˆå¿«é€Ÿä¿®å¤ï¼‰
    
    def _calculate_image_complexity(self, image) -> float:
        """è®¡ç®—å›¾åƒå¤æ‚åº¦"""
        # ç®€å•çš„è¾¹ç¼˜å¯†åº¦è®¡ç®—
        import cv2
        
        if isinstance(image, Image.Image):
            gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
        else:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
        edges = cv2.Canny(gray, 50, 150)
        complexity = np.sum(edges > 0) / edges.size
        return complexity
    
    def _build_iopaint_config(self, params):
        """æ„å»ºIOPainté…ç½®"""
        
        strategy_map = {
            'CROP': self.HDStrategy.CROP,
            'RESIZE': self.HDStrategy.RESIZE,
            'ORIGINAL': self.HDStrategy.ORIGINAL
        }
        
        config = self.Config(
            ldm_steps=params.get('ldm_steps', 50),
            ldm_sampler=self.LDMSampler.ddim,
            hd_strategy=strategy_map.get(params.get('hd_strategy', 'CROP')),
            hd_strategy_crop_margin=params.get('hd_strategy_crop_margin', 64),
            hd_strategy_crop_trigger_size=params.get('hd_strategy_crop_trigger_size', 1024),
            hd_strategy_resize_limit=params.get('hd_strategy_resize_limit', 2048),
        )
        
        return config
    
    def _get_processing_params(self, custom_config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """è·å–å¤„ç†å‚æ•°"""
        
        default_params = {
            'ldm_steps': 50,
            'hd_strategy': 'CROP',
            'hd_strategy_crop_margin': 64,
            'hd_strategy_crop_trigger_size': 1024,
            'hd_strategy_resize_limit': 2048,
            'auto_model_selection': True,
        }
        
        if custom_config:
            default_params.update(custom_config)
            
        return default_params
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = super().get_model_info()
        info.update({
            "model_type": "IOPaint_Unified",
            "current_model": self.current_model,
            "supported_models": self.available_models,
            "intelligent_selection": True,
            "framework": "IOPaint",
            "model_descriptions": {
                "zits": "æœ€ä½³ç»“æ„ä¿æŒï¼Œé€‚åˆå¤æ‚å›¾åƒ",
                "mat": "æœ€ä½³è´¨é‡ï¼Œé€‚åˆå¤§æ°´å°",
                "fcf": "å¿«é€Ÿä¿®å¤ï¼Œå¹³è¡¡æ€§èƒ½",
                "lama": "æœ€å¿«é€Ÿåº¦ï¼Œé€‚åˆå°æ°´å°"
            }
        })
        return info
    
    def get_available_models(self) -> list:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return self.available_models
    
    def get_current_model(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        return self.current_model