"""
LaMAå¤„ç†å™¨ç»Ÿä¸€ç‰ˆæœ¬
å®ç°ä¸å…¶ä»–IOPaintæ¨¡å‹ç»Ÿä¸€çš„æ¥å£ï¼ŒåŒæ—¶æ”¯æŒå¯é€‰å®‰è£…
ç¬¦åˆSIMP-LAMAåŸåˆ™çš„å®ç°
"""

import logging
import numpy as np
from typing import Dict, Any, Optional
from PIL import Image
from .base_inpainter import BaseInpainter, ModelRegistry

logger = logging.getLogger(__name__)

class LamaProcessor(BaseInpainter):
    """LaMA inpaintingå¤„ç†å™¨ - å¯é€‰ä¾èµ–å®ç°"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.model_name = "lama"
        self.saicinpainting_available = self._check_saicinpainting()
        
        if self.saicinpainting_available:
            self._load_model()
        else:
            logger.warning("âš ï¸ LaMAä½¿ç”¨IOPaint fallbackæ¨¡å¼ï¼ˆsaicinpaintingä¸å¯ç”¨ï¼‰")
            self._load_iopaint_fallback()
    
    def _check_saicinpainting(self) -> bool:
        """æ£€æŸ¥saicinpaintingä¾èµ–æ˜¯å¦å¯ç”¨"""
        try:
            import saicinpainting
            logger.info("âœ… saicinpainting available - ä½¿ç”¨åŸç”ŸLaMA")
            return True
        except ImportError:
            logger.info("â„¹ï¸ saicinpaintingä¸å¯ç”¨ - å°†ä½¿ç”¨IOPaintçš„LaMAå®ç°")
            return False
        except Exception as e:
            logger.warning(f"âš ï¸ saicinpaintingæ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def _load_model(self):
        """åŠ è½½LaMAæ¨¡å‹"""
        if self.saicinpainting_available:
            self._load_native_lama()
        else:
            self._load_iopaint_fallback()
    
    def _load_native_lama(self):
        """åŠ è½½åŸç”Ÿsaicinpainting LaMAæ¨¡å‹"""
        try:
            import torch
            import yaml
            from pathlib import Path
            from saicinpainting.training.trainers import load_checkpoint
            from saicinpainting.training.models import make_model
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # è·å–æ¨¡å‹è·¯å¾„
            model_config = self.config.get('models', {})
            model_path = model_config.get('lama_model_path', 'lama')
            
            # é…ç½®æ–‡ä»¶è·¯å¾„
            train_config_path = Path(model_path) / 'config.yaml'
            checkpoint_path = Path(model_path) / 'models' / 'best.ckpt'
            
            if not checkpoint_path.exists():
                logger.error(f"LaMA checkpoint not found: {checkpoint_path}")
                raise FileNotFoundError(f"LaMA model not found: {checkpoint_path}")
            
            # åŠ è½½é…ç½®
            with open(train_config_path, 'r') as f:
                train_config = yaml.safe_load(f)
            
            train_config['model']['input_channels'] = 4
            train_config['model']['output_channels'] = 3
            
            # åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹
            model = make_model(train_config['model'], kind='inpainting')
            model.to(self.device)
            
            checkpoint = load_checkpoint(train_config, checkpoint_path, strict=False, map_location='cpu')
            model.load_state_dict(checkpoint['state_dict'], strict=False)
            model.eval()
            
            self.model = model
            self.model_loaded = True
            logger.info(f"âœ… åŸç”ŸLaMAæ¨¡å‹åŠ è½½æˆåŠŸ: {checkpoint_path}")
            
        except Exception as e:
            logger.error(f"âŒ åŸç”ŸLaMAæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°è¯•ä½¿ç”¨IOPaint fallbackæ¨¡å¼...")
            self.saicinpainting_available = False
            self._load_iopaint_fallback()
    
    def _load_iopaint_fallback(self):
        """åŠ è½½IOPaintçš„LaMAå®ç°ä½œä¸ºfallback"""
        try:
            import torch
            from iopaint.model_manager import ModelManager
            from iopaint.schema import HDStrategy, LDMSampler, InpaintRequest as Config
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # ä½¿ç”¨IOPaintçš„LaMAå®ç°
            self.model_manager = ModelManager(name="lama", device=str(self.device))
            self.HDStrategy = HDStrategy
            self.LDMSampler = LDMSampler
            self.Config = Config
            
            self.model_loaded = True
            logger.info("âœ… IOPaint LaMA fallbackæ¨¡å¼åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ IOPaint LaMA fallbackåŠ è½½å¤±è´¥: {e}")
            self.model_loaded = False
            raise
    
    def predict(self, image: Image.Image, mask: Image.Image, config: Optional[Dict[str, Any]] = None) -> np.ndarray:
        """ç»Ÿä¸€çš„LaMAæ¨ç†æ¥å£"""
        if not self.model_loaded:
            raise RuntimeError("LaMA model not loaded")
        
        # éªŒè¯è¾“å…¥
        if not self.validate_inputs(image, mask):
            raise ValueError("Invalid inputs")
        
        # é¢„å¤„ç†
        image, mask = self.preprocess_inputs(image, mask)
        
        if self.saicinpainting_available:
            return self._predict_native_lama(image, mask, config)
        else:
            return self._predict_iopaint_lama(image, mask, config)
    
    def _predict_native_lama(self, image: Image.Image, mask: Image.Image, config: Dict[str, Any]) -> np.ndarray:
        """ä½¿ç”¨åŸç”Ÿsaicinpaintingè¿›è¡Œæ¨ç†"""
        try:
            import torch
            import cv2
            from saicinpainting.evaluation.data import pad_img_to_modulo
            from saicinpainting.evaluation.utils import move_to_device
            
            if config is None:
                config = {}
            
            # LaMAç‰¹å®šå‚æ•°
            hd_strategy = config.get('hd_strategy', 'CROP')
            hd_strategy_crop_margin = config.get('hd_strategy_crop_margin', 64)
            hd_strategy_crop_trigger_size = config.get('hd_strategy_crop_trigger_size', 1024)
            hd_strategy_resize_limit = config.get('hd_strategy_resize_limit', 2048)
            
            from ..utils.image_utils import ImageUtils
            
            # LaMAéœ€è¦BGRè¾“å…¥ï¼Œä½¿ç”¨ä¸“é—¨çš„é¢„å¤„ç†
            image_array, mask_array = ImageUtils.prepare_arrays_for_lama(image, mask)
            
            # é«˜åˆ†è¾¨ç‡å¤„ç†ç­–ç•¥
            original_size = image_array.shape[:2]
            if hd_strategy == 'CROP' and max(original_size) > hd_strategy_crop_trigger_size:
                image_array, mask_array = self._crop_for_inpainting(
                    image_array, mask_array, hd_strategy_crop_margin
                )
            elif hd_strategy == 'RESIZE' and max(original_size) > hd_strategy_resize_limit:
                scale = hd_strategy_resize_limit / max(original_size)
                new_h, new_w = int(original_size[0] * scale), int(original_size[1] * scale)
                image_array = cv2.resize(image_array, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                mask_array = cv2.resize(mask_array, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
            
            # å‡†å¤‡å¼ é‡è¾“å…¥
            img_tensor = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0).float() / 255.0
            mask_tensor = torch.from_numpy(mask_array).unsqueeze(0).unsqueeze(0).float() / 255.0
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            img_tensor = move_to_device(img_tensor, self.device)
            mask_tensor = move_to_device(mask_tensor, self.device)
            
            # å¡«å……åˆ°æ¨¡å‹è¦æ±‚çš„å°ºå¯¸
            img_tensor = pad_img_to_modulo(img_tensor, mod=8)
            mask_tensor = pad_img_to_modulo(mask_tensor, mod=8)
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                inpainted = self.model(img_tensor, mask_tensor)
                inpainted = torch.clamp(inpainted, 0, 1)
            
            # åå¤„ç†
            result = inpainted.cpu().permute(0, 2, 3, 1).numpy()[0]
            result = (result * 255).astype(np.uint8)
            
            # LaMAè¾“å‡ºBGRï¼Œè½¬æ¢ä¸ºRGB
            result = ImageUtils.postprocess_lama_result(result)
            
            # æ¢å¤åŸå§‹å°ºå¯¸
            if result.shape[:2] != original_size:
                result = cv2.resize(result, (original_size[1], original_size[0]), 
                                  interpolation=cv2.INTER_LINEAR)
            
            logger.info("âœ… åŸç”ŸLaMAæ¨ç†å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"åŸç”ŸLaMAæ¨ç†å¤±è´¥: {e}")
            raise
    
    def _predict_iopaint_lama(self, image: Image.Image, mask: Image.Image, config: Dict[str, Any]) -> np.ndarray:
        """ä½¿ç”¨IOPaint LaMAè¿›è¡Œæ¨ç†"""
        try:
            from ..utils.image_utils import ImageUtils
            
            # IOPaint LaMA fallbackä½¿ç”¨æ ‡å‡†RGBå¤„ç†
            image_array, mask_array = ImageUtils.prepare_arrays_for_iopaint(image, mask)
            
            logger.info(f"ğŸ¨ IOPaint LaMA processing: {image_array.shape}")
            
            # æ„å»ºIOPainté…ç½®
            iopaint_config = self._build_iopaint_config(config or {})
            
            # æ‰§è¡Œæ¨ç†
            result = self.model_manager(image_array, mask_array, iopaint_config)
            
            logger.info("âœ… IOPaint LaMAæ¨ç†å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"IOPaint LaMAæ¨ç†å¤±è´¥: {e}")
            raise
    
    def _build_iopaint_config(self, config: Dict[str, Any]) -> object:
        """æ„å»ºIOPainté…ç½®å¯¹è±¡"""
        # é»˜è®¤å‚æ•°
        default_config = {
            'ldm_steps': 50,
            'ldm_sampler': 'ddim',
            'hd_strategy': 'CROP',
            'hd_strategy_crop_margin': 64,
            'hd_strategy_crop_trigger_size': 1024,
            'hd_strategy_resize_limit': 2048
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        merged_config = {**default_config, **config}
        
        # æ˜ å°„ç­–ç•¥
        strategy_map = {
            'CROP': self.HDStrategy.CROP,
            'RESIZE': self.HDStrategy.RESIZE,
            'ORIGINAL': self.HDStrategy.ORIGINAL
        }
        
        # æ˜ å°„é‡‡æ ·å™¨
        sampler_map = {
            'ddim': self.LDMSampler.ddim,
            'pndm': self.LDMSampler.pndm,
            'k_euler': self.LDMSampler.k_euler,
            'k_euler_a': self.LDMSampler.k_euler_a
        }
        
        return self.Config(
            ldm_steps=merged_config['ldm_steps'],
            ldm_sampler=sampler_map.get(merged_config['ldm_sampler'], self.LDMSampler.ddim),
            hd_strategy=strategy_map.get(merged_config['hd_strategy'], self.HDStrategy.CROP),
            hd_strategy_crop_margin=merged_config['hd_strategy_crop_margin'],
            hd_strategy_crop_trigger_size=merged_config['hd_strategy_crop_trigger_size'],
            hd_strategy_resize_limit=merged_config['hd_strategy_resize_limit']
        )
    
    def _crop_for_inpainting(self, image: np.ndarray, mask: np.ndarray, margin: int) -> tuple:
        """ä¸ºinpaintingè£å‰ªå›¾åƒ"""
        import cv2
        
        # æ‰¾åˆ°maskçš„è¾¹ç•Œæ¡†
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return image, mask
        
        # è®¡ç®—è¾¹ç•Œæ¡†
        x, y, w, h = cv2.boundingRect(contours[0])
        for contour in contours[1:]:
            x1, y1, w1, h1 = cv2.boundingRect(contour)
            x = min(x, x1)
            y = min(y, y1)
            w = max(w, x1 + w1 - x)
            h = max(h, y1 + h1 - y)
        
        # æ·»åŠ è¾¹è·
        x = max(0, x - margin)
        y = max(0, y - margin)
        w = min(image.shape[1] - x, w + 2 * margin)
        h = min(image.shape[0] - y, h + 2 * margin)
        
        # è£å‰ª
        cropped_image = image[y:y+h, x:x+w]
        cropped_mask = mask[y:y+h, x:x+w]
        
        return cropped_image, cropped_mask
    
    def cleanup_resources(self):
        """æ¸…ç†LaMAèµ„æº"""
        try:
            if self.saicinpainting_available:
                if hasattr(self, 'model') and self.model is not None:
                    if hasattr(self.model, 'cpu'):
                        self.model.cpu()
                    del self.model
                self.model = None
            else:
                if hasattr(self, 'model_manager') and self.model_manager is not None:
                    del self.model_manager
                self.model_manager = None
            
            self.model_loaded = False
            
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info("âœ… LaMA processor resources cleaned up")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Error during LaMA processor cleanup: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–LaMAæ¨¡å‹ä¿¡æ¯"""
        info = super().get_model_info()
        info.update({
            'model_name': self.model_name,
            'saicinpainting_available': self.saicinpainting_available,
            'mode': 'native' if self.saicinpainting_available else 'iopaint_fallback'
        })
        return info

# æ³¨å†ŒLaMAæ¨¡å‹åˆ°æ¨¡å‹æ³¨å†Œè¡¨
ModelRegistry.register("lama", LamaProcessor)