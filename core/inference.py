"""
æ¨ç†é€»è¾‘æ¨¡å—
è´Ÿè´£AIæ¨¡å‹æ¨ç†ã€maskç”Ÿæˆå’Œinpaintingå¤„ç†
åŸºäºåŸå§‹ web_backend.py çš„å®Œæ•´ LaMA é›†æˆ
"""

import time
import logging
import yaml
import io
from typing import Dict, Any, Optional, Union
from PIL import Image
import numpy as np
from pathlib import Path

from core.utils.image_utils import ImageProcessor
from core.models.lama_processor import LamaProcessor
from core.models.powerpaint_processor import PowerPaintProcessor

logger = logging.getLogger(__name__)

class ProcessingResult:
    """å¤„ç†ç»“æœæ•°æ®ç±»"""
    def __init__(self, success: bool, result_image: Optional[Image.Image] = None,
                 mask_image: Optional[Image.Image] = None, error_message: Optional[str] = None,
                 processing_time: float = 0.0):
        self.success = success
        self.result_image = result_image
        self.mask_image = mask_image
        self.error_message = error_message
        self.processing_time = processing_time

class CustomMaskGenerator:
    """è‡ªå®šä¹‰maskç”Ÿæˆå™¨ - åŸºäº Watermark_sam æ¨¡å‹"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model = None
        self.device = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½è‡ªå®šä¹‰åˆ†å‰²æ¨¡å‹"""
        try:
            import torch
            import segmentation_models_pytorch as smp
            import albumentations as A
            import cv2
            from albumentations.pytorch import ToTensorV2
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # å®šä¹‰æ¨¡å‹æ¶æ„
            class WMModel(torch.nn.Module):
                def __init__(self, freeze_encoder=True):
                    super().__init__()
                    self.net = smp.create_model("FPN", encoder_name="mit_b5", in_channels=3, classes=1)
                    if freeze_encoder:
                        for p in self.net.encoder.parameters():
                            p.requires_grad = False

                def forward(self, x):
                    return self.net(x)
            
            # åŠ è½½æ¨¡å‹
            self.model = WMModel(freeze_encoder=False).to(self.device)
            
            # åŠ è½½checkpoint
            mask_config = self.config['mask_generator']
            ckpt_path = mask_config['mask_model_path']
            
            if not Path(ckpt_path).exists():
                logger.error(f"Custom mask model not found: {ckpt_path}")
                logger.error("Custom mask generation will not be available")
                self.model = None
                raise FileNotFoundError(f"Custom mask model not found: {ckpt_path}")
                
            ckpt = torch.load(ckpt_path, map_location=self.device)
            state_dict = {k.replace("net.", ""): v for k, v in ckpt["state_dict"].items() if k.startswith("net.")}
            self.model.net.load_state_dict(state_dict)
            self.model.eval()
            
            # Setup preprocessing
            mask_config = self.config['mask_generator']
            self.image_size = mask_config['image_size']
            self.imagenet_mean = mask_config['imagenet_mean']
            self.imagenet_std = mask_config['imagenet_std']
            self.mask_threshold = mask_config['mask_threshold']
            
            self.aug_val = A.Compose([
                A.LongestMaxSize(max_size=self.image_size),
                A.PadIfNeeded(min_height=self.image_size, min_width=self.image_size, border_mode=cv2.BORDER_CONSTANT),
                A.Normalize(mean=self.imagenet_mean, std=self.imagenet_std, max_pixel_value=255.0),
                ToTensorV2(),
            ])
            
            logger.info(f"âœ… Custom mask model loaded from: {ckpt_path}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load custom mask model: {e}")
            # Clean up any partially loaded resources
            if hasattr(self, 'model') and self.model is not None:
                if hasattr(self.model, 'cpu'):
                    self.model.cpu()
                del self.model
            self.model = None
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    def generate_mask(self, image: Image.Image, mask_params: Dict[str, Any] = None) -> Image.Image:
        """ç”Ÿæˆæ°´å°mask"""
        if self.model is None:
            logger.warning("Custom mask model not available, returning empty mask")
            return Image.new('L', image.size, 0)
        
        try:
            import torch
            import cv2
            
            # ä½¿ç”¨åŠ¨æ€å‚æ•°æˆ–é»˜è®¤å€¼
            mask_threshold = mask_params.get('mask_threshold', self.mask_threshold) if mask_params else self.mask_threshold
            dilate_size = mask_params.get('mask_dilate_kernel_size', 3) if mask_params else 3
            dilate_iterations = mask_params.get('mask_dilate_iterations', 1) if mask_params else 1
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            image_rgb = np.array(image.convert("RGB"))
            orig_h, orig_w = image_rgb.shape[:2]
            
            # é¢„å¤„ç†
            sample = self.aug_val(image=image_rgb, mask=None)
            img_tensor = sample["image"].unsqueeze(0).to(self.device)
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                pred_mask = self.model(img_tensor)
                pred_mask = torch.sigmoid(pred_mask).squeeze().cpu().numpy()
            
            # åå¤„ç†
            scale = min(self.image_size / orig_h, self.image_size / orig_w)
            new_h, new_w = int(orig_h * scale), int(orig_w * scale)
            
            pad_top = (self.image_size - new_h) // 2
            pad_left = (self.image_size - new_w) // 2
            
            pred_crop = pred_mask[pad_top:pad_top+new_h, pad_left:pad_left+new_w]
            pred_mask = cv2.resize(pred_crop, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)
            
            # äºŒå€¼åŒ–
            binary_mask = (pred_mask > mask_threshold).astype(np.uint8) * 255
            
            # è†¨èƒ€å¤„ç†
            if dilate_size > 0:
                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_size, dilate_size))
                binary_mask = cv2.dilate(binary_mask, kernel, iterations=dilate_iterations)
            
            return Image.fromarray(binary_mask, mode='L')
            
        except Exception as e:
            logger.error(f"Custom mask generation failed: {e}")
            return Image.new('L', image.size, 0)

class FlorenceMaskGenerator:
    """Florence-2 maskç”Ÿæˆå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.florence_model = None
        self.florence_processor = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½Florence-2æ¨¡å‹"""
        try:
            import torch
            from transformers import AutoProcessor, AutoModelForCausalLM
            
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model_name = self.config['models']['florence_model']
            
            self.florence_model = AutoModelForCausalLM.from_pretrained(
                model_name, trust_remote_code=True
            ).to(device).eval()
            self.florence_processor = AutoProcessor.from_pretrained(
                model_name, trust_remote_code=True
            )
            logger.info(f"âœ… Florence-2 model loaded: {model_name}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load Florence-2 model: {e}")
            self.florence_model = None
            self.florence_processor = None
    
    def generate_mask(self, image: Image.Image, mask_params: Dict[str, Any] = None) -> Image.Image:
        """ä½¿ç”¨Florence-2ç”Ÿæˆmask"""
        if self.florence_model is None:
            logger.warning("Florence-2 model not available, returning empty mask")
            return Image.new('L', image.size, 0)
        
        try:
            # è·å–å‚æ•°
            max_bbox_percent = mask_params.get('max_bbox_percent', 10.0) if mask_params else 10.0
            detection_prompt = mask_params.get('detection_prompt', 'watermark') if mask_params else 'watermark'
            
            # TODO: å®ç°Florence-2æ£€æµ‹é€»è¾‘
            # ç”±äºç¼ºå°‘utilsæ¨¡å—ï¼Œæš‚æ—¶è¿”å›ç©ºmask
            logger.warning("Florence-2 detection logic not implemented yet")
            return Image.new('L', image.size, 0)
            
        except Exception as e:
            logger.error(f"Florence mask generation failed: {e}")
            return Image.new('L', image.size, 0)

class WatermarkProcessor:
    """æ°´å°å¤„ç†ä¸»ç±» - åŸºäºåŸå§‹ web_backend.py"""
    
    def __init__(self, config_path: Optional[str] = None):
        if config_path is None:
            config_path = Path(__file__).parent.parent / "web_config.yaml"
        self.config_path = config_path
        self.config = self._load_config(config_path)
        self._resources = []  # Track resources for cleanup
    
    def __enter__(self):
        """Context manager entry"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit with automatic cleanup"""
        self.cleanup_resources()
    
    def cleanup_resources(self):
        """Clean up all processor resources"""
        try:
            # Clean up LaMA processor
            if hasattr(self, 'lama_processor') and self.lama_processor:
                if hasattr(self.lama_processor, 'cleanup_resources'):
                    self.lama_processor.cleanup_resources()
            
            # Clean up mask generator if it has cleanup method
            if hasattr(self, 'mask_generator') and hasattr(self.mask_generator, 'cleanup_resources'):
                self.mask_generator.cleanup_resources()
            
            # Clear CUDA cache
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info("âœ… WatermarkProcessor resources cleaned up")
        except Exception as e:
            logger.warning(f"âš ï¸ Error during WatermarkProcessor cleanup: {e}")
    
        # Initialize components
        self._init_components()
    
    def _init_components(self):
        """Initialize processor components"""
        # åˆå§‹åŒ–maskç”Ÿæˆå™¨
        mask_type = self.config['mask_generator']['model_type']
        try:
            if mask_type == "custom":
                self.mask_generator = CustomMaskGenerator(self.config)
            else:
                self.mask_generator = FlorenceMaskGenerator(self.config)
        except Exception as e:
            logger.error(f"Failed to initialize mask generator: {e}")
            # æä¾›é™çº§æ–¹æ¡ˆ - ä½¿ç”¨åŸºç¡€çš„ç©ºmaskç”Ÿæˆå™¨
            self.mask_generator = self._create_fallback_mask_generator()
            logger.info("Using fallback mask generator")
        
        # åˆå§‹åŒ–LaMAå¤„ç†å™¨
        try:
            self.lama_processor = LamaProcessor(self.config)
        except Exception as e:
            logger.error(f"Failed to initialize LaMA processor: {e}")
            raise RuntimeError(f"Critical failure: LaMA processor initialization failed: {e}")
        
        logger.info(f"âœ… WatermarkProcessor initialized with {mask_type} mask generator")
    
    def _create_fallback_mask_generator(self):
        """åˆ›å»ºé™çº§maskç”Ÿæˆå™¨"""
        class FallbackMaskGenerator:
            def __init__(self):
                pass
            
            def generate_mask(self, image: Image.Image, mask_params: Dict[str, Any] = None) -> Image.Image:
                logger.warning("Using fallback mask generator - returning empty mask")
                return Image.new('L', image.size, 0)
        
        return FallbackMaskGenerator()
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                logger.info(f"âœ… Config loaded from: {config_path}")
                return config
        except Exception as e:
            logger.warning(f"Config file {config_path} not found, using defaults")
            # ä½¿ç”¨ConfigManagerçš„é»˜è®¤é…ç½®
            from config.config import ConfigManager
            config_manager = ConfigManager()
            return self._build_default_config(config_manager)
    
    def _build_default_config(self, config_manager) -> Dict[str, Any]:
        """æ„å»ºé»˜è®¤é…ç½®"""
        return {
            'mask_generator': {
                'model_type': 'custom',
                'mask_model_path': '/home/duolaameng/SAM_Remove/Watermark_sam/output/checkpoints/epoch=071-valid_iou=0.7267.ckpt',
                'image_size': 768,
                'imagenet_mean': [0.485, 0.456, 0.406],
                'imagenet_std': [0.229, 0.224, 0.225],
                'mask_threshold': config_manager.app_config.default_mask_threshold,
            },
            'models': {
                'florence_model': 'microsoft/Florence-2-large',
                'lama_model': config_manager.get_model_config().get('lama_model', 'lama')
            }
        }
    
    def process_image(self, 
                     image: Image.Image,
                     transparent: bool = False,
                     max_bbox_percent: float = 10.0,
                     force_format: Optional[str] = None,
                     custom_inpaint_config: Optional[Dict[str, Any]] = None) -> ProcessingResult:
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        start_time = time.time()
        
        try:
            logger.info("ğŸš€ å¼€å§‹å¤„ç†å›¾åƒ...")
            logger.info(f"ğŸ“¸ è¾“å…¥å›¾åƒ: size={image.size}, mode={image.mode}")
            logger.info(f"ğŸ¯ å¤„ç†æ¨¡å¼: {'é€æ˜' if transparent else 'ä¿®å¤'}")
            
            # ç”Ÿæˆmask
            logger.info("ğŸ­ å¼€å§‹ç”Ÿæˆmask...")
            mask_params = {'max_bbox_percent': max_bbox_percent}
            mask_image = self.mask_generator.generate_mask(image, mask_params)
            
            # éªŒè¯mask
            mask_array = np.array(mask_image)
            white_pixels = np.sum(mask_array > 128)
            total_pixels = mask_array.size
            mask_coverage = white_pixels / total_pixels * 100
            logger.info(f"ğŸ” MaskéªŒè¯: è¦†ç›–ç‡={mask_coverage:.2f}%")
            
            if transparent:
                logger.info("ğŸ«¥ åº”ç”¨é€æ˜å¤„ç†...")
                result_image = self._make_region_transparent(image, mask_image)
            else:
                logger.info("ğŸ¨ åº”ç”¨LaMAä¿®å¤å¤„ç†...")
                if custom_inpaint_config is None:
                    custom_inpaint_config = {}
                result_image_array = self.lama_processor.predict(image, mask_image, custom_inpaint_config)
                result_image = Image.fromarray(result_image_array)
            
            processing_time = time.time() - start_time
            logger.info(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return ProcessingResult(
                success=True,
                result_image=result_image,
                mask_image=mask_image,
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}")
            return ProcessingResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time
            )
    
    def _make_region_transparent(self, image: Image.Image, mask: Image.Image) -> Image.Image:
        """ä½¿åŒºåŸŸé€æ˜"""
        image = image.convert("RGBA")
        mask = mask.convert("L")
        transparent_image = Image.new("RGBA", image.size)
        
        for x in range(image.width):
            for y in range(image.height):
                if mask.getpixel((x, y)) > 0:
                    transparent_image.putpixel((x, y), (0, 0, 0, 0))
                else:
                    transparent_image.putpixel((x, y), image.getpixel((x, y)))
        
        return transparent_image
    
    def _process_with_lama(self, image: Image.Image, mask: Image.Image, lama_config: Dict[str, Any]) -> Image.Image:
        """ä½¿ç”¨LaMAè¿›è¡Œinpainting - å…¼å®¹æ¥å£"""
        result_array = self.lama_processor.predict(image, mask, lama_config)
        return Image.fromarray(result_array)
    
    def get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        import torch
        import psutil
        
        info = {
            "cuda_available": torch.cuda.is_available(),
            "lama_loaded": self.lama_processor.model_loaded,
            "mask_generator": self.config['mask_generator']['model_type'],
            "ram_usage": f"{psutil.virtual_memory().percent:.1f}%",
            "cpu_usage": f"{psutil.cpu_percent():.1f}%"
        }
        
        if torch.cuda.is_available():
            gpu_info = torch.cuda.get_device_properties(0)
            vram_total = gpu_info.total_memory // (1024 ** 2)
            vram_used = torch.cuda.memory_reserved(0) // (1024 ** 2)
            info["vram_usage"] = f"{vram_used}/{vram_total} MB"
            info["gpu_name"] = gpu_info.name
        
        return info

class EnhancedWatermarkProcessor:
    """å¢å¼ºçš„æ°´å°å¤„ç†å™¨ - æ”¯æŒ PowerPaint"""
    
    def __init__(self, base_processor: WatermarkProcessor):
        self.base_processor = base_processor
        self.powerpaint_processor = None
        self._load_powerpaint_processor()
    
    def _load_powerpaint_processor(self):
        """Load PowerPaint processor"""
        try:
            # Create PowerPaint config
            config = {
                'models': {
                    'powerpaint_model_path': './models/powerpaint_v2_real/realisticVisionV60B1_v51VAE'
                },
                'powerpaint_config': {
                    'use_fp16': True,
                    'enable_attention_slicing': True,
                    'enable_memory_efficient_attention': True,
                    'enable_vae_slicing': False
                }
            }
            
            self.powerpaint_processor = PowerPaintProcessor(config)
            logger.info("PowerPaint processor loaded successfully")
            
        except Exception as e:
            logger.warning(f"PowerPaint processor loading failed: {e}")
            logger.info("PowerPaint functionality will not be available")
    
    def process_image_with_params(self, 
                                image: Image.Image,
                                mask_model: str,
                                mask_params: Dict[str, Any],
                                inpaint_params: Dict[str, Any],
                                performance_params: Dict[str, Any],
                                transparent: bool = False) -> ProcessingResult:
        """ä½¿ç”¨è¯¦ç»†å‚æ•°å¤„ç†å›¾åƒ"""
        start_time = time.time()
        
        try:
            logger.info("ğŸš€ å¼€å§‹å¢å¼ºå¤„ç†æµç¨‹...")
            logger.info(f"ğŸ­ Maskæ¨¡å‹: {mask_model}")
            logger.info(f"âš™ï¸ Inpaintå‚æ•°: {inpaint_params}")
            
            # ç”Ÿæˆmask
            if mask_model == "upload":
                mask_image = self._generate_uploaded_mask(image, mask_params)
            elif mask_model == "florence2":
                mask_image = self.base_processor.mask_generator.generate_mask(image, mask_params)
            else:  # custom
                mask_image = self.base_processor.mask_generator.generate_mask(image, mask_params)
            
            # éªŒè¯mask
            mask_array = np.array(mask_image)
            white_pixels = np.sum(mask_array > 128)
            total_pixels = mask_array.size
            mask_coverage = white_pixels / total_pixels * 100
            logger.info(f"ğŸ” MaskéªŒè¯: è¦†ç›–ç‡={mask_coverage:.2f}%")
            
            # åº”ç”¨å¤„ç†
            if transparent:
                logger.info("ğŸ«¥ åº”ç”¨é€æ˜å¤„ç†...")
                result_image = self.base_processor._make_region_transparent(image, mask_image)
            else:
                inpaint_model = inpaint_params.get('inpaint_model', 'lama')
                
                if inpaint_model == 'powerpaint' and self.powerpaint_processor and self.powerpaint_processor.model_loaded:
                    logger.info("ğŸ¨ åº”ç”¨PowerPaintå¤„ç†...")
                    result_array = self.powerpaint_processor.predict(image, mask_image, inpaint_params)
                    result_image = Image.fromarray(result_array)
                else:
                    logger.info("ğŸ¨ åº”ç”¨LaMAå¤„ç†...")
                    result_array = self.base_processor.lama_processor.predict(image, mask_image, inpaint_params)
                    result_image = Image.fromarray(result_array)
            
            processing_time = time.time() - start_time
            logger.info(f"âœ… å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            return ProcessingResult(
                success=True,
                result_image=result_image,
                mask_image=mask_image,
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ å¢å¼ºå¤„ç†å¤±è´¥: {e}")
            return ProcessingResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time
            )
    
    def _generate_uploaded_mask(self, image: Image.Image, params: Dict[str, Any]) -> Image.Image:
        """å¤„ç†ä¸Šä¼ çš„mask"""
        uploaded_mask = params.get('uploaded_mask')
        if not uploaded_mask:
            raise ValueError("No mask file uploaded")
        
        # Validate uploaded mask
        if hasattr(uploaded_mask, 'size') and uploaded_mask.size == 0:
            raise ValueError("Uploaded mask file is empty")
        
        try:
            logger.info(f"ğŸ“‚ å¤„ç†ä¸Šä¼ çš„maskæ–‡ä»¶")
            logger.info(f"ğŸ“ åŸå›¾å°ºå¯¸: {image.size}")
            
            # è¯»å–ä¸Šä¼ çš„mask
            if hasattr(uploaded_mask, 'read'):
                # Streamlit UploadedFileå¯¹è±¡
                uploaded_mask.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                mask = Image.open(uploaded_mask)
            else:
                # æ–‡ä»¶è·¯å¾„
                mask = Image.open(uploaded_mask)
                
        except Exception as e:
            raise ValueError(f"Failed to open uploaded mask file: {e}")
        
        # Validate mask after loading
        if mask.size[0] <= 0 or mask.size[1] <= 0:
            raise ValueError("Invalid mask dimensions")
        
        logger.info(f"ğŸ“ åŸå§‹maskå°ºå¯¸: {mask.size}")
        logger.info(f"ğŸ¨ åŸå§‹maskæ¨¡å¼: {mask.mode}")
        
        # ç¡®ä¿maskæ˜¯ç°åº¦å›¾åƒ
        if mask.mode != 'L':
            mask = mask.convert('L')
            logger.info(f"ğŸ”„ è½¬æ¢maskä¸ºç°åº¦æ¨¡å¼: {mask.mode}")
        
        # è°ƒæ•´maskå°ºå¯¸ä»¥åŒ¹é…å›¾åƒ
        if mask.size != image.size:
            logger.info(f"ğŸ“ è°ƒæ•´maskå°ºå¯¸: {mask.size} -> {image.size}")
            mask = mask.resize(image.size, Image.LANCZOS)
        else:
            logger.info(f"âœ… Maskå°ºå¯¸å·²åŒ¹é…: {mask.size}")
        
        # æ£€æŸ¥maskå†…å®¹
        mask_array = np.array(mask)
        white_pixels = np.sum(mask_array > 128)
        total_pixels = mask_array.size
        mask_coverage = white_pixels / total_pixels * 100
        logger.info(f"ğŸ” Maskå†…å®¹åˆ†æ: ç™½è‰²åƒç´ ={white_pixels}, æ€»åƒç´ ={total_pixels}, è¦†ç›–ç‡={mask_coverage:.2f}%")
        logger.info(f"ğŸ“Š Maskåƒç´ å€¼èŒƒå›´: {mask_array.min()} - {mask_array.max()}")
        
        # åº”ç”¨é¢å¤–çš„è†¨èƒ€å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        dilate_size = params.get('mask_dilate_kernel_size', 0)
        if dilate_size > 0:
            import cv2
            logger.info(f"ğŸ”§ åº”ç”¨è†¨èƒ€å¤„ç†: kernel_size={dilate_size}")
            mask_array = np.array(mask)
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_size, dilate_size))
            mask_array = cv2.dilate(mask_array, kernel, iterations=1)
            mask = Image.fromarray(mask_array, mode='L')
            
            # æ£€æŸ¥è†¨èƒ€åçš„mask
            white_pixels_after = np.sum(mask_array > 128)
            coverage_after = white_pixels_after / total_pixels * 100
            logger.info(f"ğŸ” è†¨èƒ€åMaskåˆ†æ: ç™½è‰²åƒç´ ={white_pixels_after}, è¦†ç›–ç‡={coverage_after:.2f}%")
        
        logger.info(f"âœ… æœ€ç»ˆmaskå°ºå¯¸: {mask.size}, æ¨¡å¼: {mask.mode}")
        return mask

class InferenceManager:
    """æ¨ç†ç®¡ç†å™¨"""
    
    def __init__(self, config_manager, config_path: Optional[str] = None):
        self.config_manager = config_manager
        self.config_path = config_path
        self.processor = None
        self.enhanced_processor = None
    
    def load_processor(self) -> bool:
        """åŠ è½½å¤„ç†å™¨"""
        try:
            self.processor = WatermarkProcessor(self.config_path)
            self.enhanced_processor = EnhancedWatermarkProcessor(self.processor)
            logger.info("âœ… Inference manager loaded successfully")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to load inference manager: {e}")
            return False
    
    def process_image(self, 
                     image: Image.Image,
                     mask_model: str,
                     mask_params: Dict[str, Any],
                     inpaint_params: Dict[str, Any],
                     performance_params: Dict[str, Any],
                     transparent: bool = False) -> ProcessingResult:
        """å¤„ç†å›¾åƒ"""
        if self.enhanced_processor is None:
            return ProcessingResult(
                success=False,
                error_message="Processor not loaded"
            )
        
        return self.enhanced_processor.process_image_with_params(
            image=image,
            mask_model=mask_model,
            mask_params=mask_params,
            inpaint_params=inpaint_params,
            performance_params=performance_params,
            transparent=transparent
        )