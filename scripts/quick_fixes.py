#!/usr/bin/env python3
"""
WatermarkRemover-AI å¿«é€Ÿä¿®å¤è„šæœ¬
è§£å†³CUDAå†…å­˜ç®¡ç†ã€LaMAé™çº§å’Œé¢œè‰²ç©ºé—´é—®é¢˜
"""

import os
import sys
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def fix_cuda_memory_management():
    """ä¿®å¤CUDAå†…å­˜ç®¡ç†é—®é¢˜"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ”§ ä¿®å¤CUDAå†…å­˜ç®¡ç†...")
    
    # 1. åˆ›å»ºç¯å¢ƒå˜é‡è®¾ç½®è„šæœ¬
    env_script = project_root / "scripts" / "set_cuda_env.sh"
    env_content = """#!/bin/bash
# CUDAå†…å­˜ç®¡ç†ä¼˜åŒ–
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_LAUNCH_BLOCKING=1
export CUDA_VISIBLE_DEVICES=0

# å¯åŠ¨åº”ç”¨
cd "$(dirname "$0")/.."
streamlit run interfaces/web/main.py --server.port 8501
"""
    
    with open(env_script, 'w') as f:
        f.write(env_content)
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod(env_script, 0o755)
    logger.info(f"âœ… åˆ›å»ºCUDAç¯å¢ƒè„šæœ¬: {env_script}")
    
    # 2. åˆ›å»ºå†…å­˜ç›‘æ§å·¥å…·
    memory_monitor = project_root / "core" / "utils" / "memory_monitor.py"
    monitor_content = '''"""
GPUå†…å­˜ç›‘æ§å·¥å…·
"""

import torch
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)

class MemoryMonitor:
    """GPUå†…å­˜ç›‘æ§å™¨"""
    
    @staticmethod
    def get_gpu_memory_info() -> Optional[Dict[str, float]]:
        """è·å–GPUå†…å­˜ä¿¡æ¯"""
        if not torch.cuda.is_available():
            return None
            
        try:
            allocated = torch.cuda.memory_allocated() / 1024**3
            reserved = torch.cuda.memory_reserved() / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            free = total - reserved
            
            return {
                'allocated_gb': allocated,
                'reserved_gb': reserved,
                'total_gb': total,
                'free_gb': free,
                'usage_percent': (reserved / total) * 100
            }
        except Exception as e:
            logger.warning(f"Failed to get GPU memory info: {e}")
            return None
    
    @staticmethod
    def clear_cache():
        """æ¸…ç†CUDAç¼“å­˜"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.info("âœ… CUDA cache cleared")
    
    @staticmethod
    def check_memory_warning(threshold_gb: float = 2.0) -> bool:
        """æ£€æŸ¥å†…å­˜æ˜¯å¦ä¸è¶³"""
        info = MemoryMonitor.get_gpu_memory_info()
        if info and info['free_gb'] < threshold_gb:
            logger.warning(f"âš ï¸ GPU memory low: {info['free_gb']:.2f}GB free")
            return True
        return False
    
    @staticmethod
    def log_memory_status():
        """è®°å½•å†…å­˜çŠ¶æ€"""
        info = MemoryMonitor.get_gpu_memory_info()
        if info:
            logger.info(f"GPU Memory: {info['allocated_gb']:.2f}GB allocated, "
                       f"{info['reserved_gb']:.2f}GB reserved, "
                       f"{info['free_gb']:.2f}GB free")
'''
    
    with open(memory_monitor, 'w') as f:
        f.write(monitor_content)
    
    logger.info(f"âœ… åˆ›å»ºå†…å­˜ç›‘æ§å·¥å…·: {memory_monitor}")

def fix_lama_processor():
    """ä¿®å¤LaMAå¤„ç†å™¨ï¼Œå®ç°å¯é€‰æ”¯æŒ"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ”§ ä¿®å¤LaMAå¤„ç†å™¨...")
    
    # åˆ›å»ºå¯é€‰çš„LaMAå¤„ç†å™¨
    lama_fix = project_root / "core" / "models" / "lama_processor_fixed.py"
    lama_content = '''"""
LaMAå¤„ç†å™¨ä¿®å¤ç‰ˆæœ¬ - æ”¯æŒå¯é€‰å®‰è£…
"""

import logging
import time
import yaml
import numpy as np
from typing import Dict, Any, Optional
from PIL import Image
from pathlib import Path

logger = logging.getLogger(__name__)

class OptionalLamaProcessor:
    """å¯é€‰çš„LaMAå¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model = None
        self.device = None
        self.model_loaded = False
        self.available = self._check_dependencies()
        
        if self.available:
            self._load_model()
        else:
            logger.warning("âš ï¸ LaMA dependencies not available, processor disabled")
    
    def _check_dependencies(self) -> bool:
        """æ£€æŸ¥LaMAä¾èµ–æ˜¯å¦å¯ç”¨"""
        try:
            import saicinpainting
            return True
        except ImportError:
            logger.warning("âŒ saicinpainting not available")
            return False
        except Exception as e:
            logger.warning(f"âŒ LaMA dependency check failed: {e}")
            return False
    
    def _load_model(self):
        """åŠ è½½LaMAæ¨¡å‹"""
        if not self.available:
            return
            
        try:
            import torch
            import cv2
            from saicinpainting.evaluation.data import pad_img_to_modulo
            from saicinpainting.evaluation.utils import move_to_device
            from saicinpainting.evaluation.data import load_image, load_mask, get_img
            from saicinpainting.training.trainers import load_checkpoint
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # è·å–æ¨¡å‹é…ç½®
            model_config = self.config.get('models', {})
            model_path = model_config.get('lama_model', 'lama')
            
            # åŠ è½½æ¨¡å‹
            train_config_path = Path(model_path) / 'config.yaml'
            model_path = Path(model_path) / 'models' / 'best.ckpt'
            
            if not model_path.exists():
                logger.error(f"LaMA model not found: {model_path}")
                raise FileNotFoundError(f"LaMA model not found: {model_path}")
            
            with open(train_config_path, 'r') as f:
                train_config = yaml.safe_load(f)
            
            train_config['model']['input_channels'] = 4
            train_config['model']['output_channels'] = 3
            
            # åˆ›å»ºæ¨¡å‹
            from saicinpainting.training.data.datasets import make_default_val_dataset
            from saicinpainting.training.models import make_model
            
            model = make_model(train_config['model'], kind='inpainting')
            model.to(self.device)
            
            # åŠ è½½checkpoint
            checkpoint = load_checkpoint(train_config, model_path, strict=False, map_location='cpu')
            model.load_state_dict(checkpoint['state_dict'], strict=False)
            model.eval()
            
            self.model = model
            self.model_loaded = True
            logger.info(f"âœ… LaMA model loaded from: {model_path}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load LaMA model: {e}")
            self.model = None
            self.model_loaded = False
    
    def predict(self, image: Image.Image, mask: Image.Image, config: Dict[str, Any] = None) -> np.ndarray:
        """ä½¿ç”¨LaMAè¿›è¡Œinpainting"""
        if not self.available:
            raise RuntimeError("LaMA not available - dependencies missing")
            
        if not self.model_loaded:
            raise RuntimeError("LaMA model not loaded")
        
        try:
            import torch
            import cv2
            from saicinpainting.evaluation.data import pad_img_to_modulo
            from saicinpainting.evaluation.utils import move_to_device
            from saicinpainting.evaluation.data import load_image, load_mask, get_img
            
            # ä½¿ç”¨é»˜è®¤é…ç½®æˆ–è‡ªå®šä¹‰é…ç½®
            if config is None:
                config = {}
            
            # è·å–å‚æ•°
            ldm_steps = config.get('ldm_steps', 50)
            ldm_sampler = config.get('ldm_sampler', 'ddim')
            hd_strategy = config.get('hd_strategy', 'CROP')
            hd_strategy_crop_margin = config.get('hd_strategy_crop_margin', 64)
            hd_strategy_crop_trigger_size = config.get('hd_strategy_crop_trigger_size', 1024)
            hd_strategy_resize_limit = config.get('hd_strategy_resize_limit', 2048)
            
            # è½¬æ¢å›¾åƒæ ¼å¼ - LaMAéœ€è¦BGRè¾“å…¥
            image_array = np.array(image.convert("RGB"))
            image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)  # RGB to BGR
            mask_array = np.array(mask.convert("L"))
            
            # ç¡®ä¿maskæ˜¯äºŒå€¼çš„
            mask_array = (mask_array > 128).astype(np.uint8) * 255
            
            # å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒ
            if hd_strategy == 'CROP' and max(image_array.shape[:2]) > hd_strategy_crop_trigger_size:
                # è£å‰ªç­–ç•¥
                image_array, mask_array = self._crop_for_inpainting(
                    image_array, mask_array, hd_strategy_crop_margin
                )
            elif hd_strategy == 'RESIZE' and max(image_array.shape[:2]) > hd_strategy_resize_limit:
                # ç¼©æ”¾ç­–ç•¥
                scale = hd_strategy_resize_limit / max(image_array.shape[:2])
                new_h, new_w = int(image_array.shape[0] * scale), int(image_array.shape[1] * scale)
                image_array = cv2.resize(image_array, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                mask_array = cv2.resize(mask_array, (new_w, new_h), interpolation=cv2.INTER_NEAREST)
            
            # å‡†å¤‡è¾“å…¥
            img = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0).float() / 255.0
            mask = torch.from_numpy(mask_array).unsqueeze(0).unsqueeze(0).float() / 255.0
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            img = move_to_device(img, self.device)
            mask = move_to_device(mask, self.device)
            
            # å¡«å……åˆ°æ¨¡å‹è¦æ±‚çš„å°ºå¯¸
            img = pad_img_to_modulo(img, mod=8)
            mask = pad_img_to_modulo(mask, mod=8)
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                inpainted = self.model(img, mask)
                inpainted = torch.clamp(inpainted, 0, 1)
            
            # åå¤„ç† - LaMAè¾“å‡ºBGRï¼Œè½¬æ¢ä¸ºRGB
            inpainted = inpainted.cpu().permute(0, 2, 3, 1).numpy()[0]
            inpainted = (inpainted * 255).astype(np.uint8)
            inpainted = cv2.cvtColor(inpainted, cv2.COLOR_BGR2RGB)  # BGR to RGB
            
            # æ¢å¤åŸå§‹å°ºå¯¸
            if inpainted.shape[:2] != image_array.shape[:2]:
                inpainted = cv2.resize(inpainted, (image_array.shape[1], image_array.shape[0]), 
                                     interpolation=cv2.INTER_LINEAR)
            
            return inpainted
            
        except Exception as e:
            logger.error(f"LaMA prediction failed: {e}")
            raise
    
    def _crop_for_inpainting(self, image: np.ndarray, mask: np.ndarray, margin: int) -> tuple:
        """ä¸ºinpaintingè£å‰ªå›¾åƒ"""
        import cv2
        
        # æ‰¾åˆ°maskçš„è¾¹ç•Œæ¡†
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            return image, mask
        
        # è®¡ç®—è¾¹ç•Œæ¡†
        x, y, w, h = cv2.boundingRect(contours[0])
        for contour in contours[1:]:
            x1, y1, w1, h1 = cv2.boundingRect(contour)
            x = min(x, x1)
            y = min(y, y1)
            w = max(w, x1 + w1 - x)
            h = max(h, y1 + h1 - y)
        
        # æ·»åŠ è¾¹è·
        x = max(0, x - margin)
        y = max(0, y - margin)
        w = min(image.shape[1] - x, w + 2 * margin)
        h = min(image.shape[0] - y, h + 2 * margin)
        
        # è£å‰ª
        cropped_image = image[y:y+h, x:x+w]
        cropped_mask = mask[y:y+h, x:x+w]
        
        return cropped_image, cropped_mask
    
    def cleanup_resources(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.model is not None:
                if hasattr(self.model, 'cpu'):
                    self.model.cpu()
                del self.model
            self.model = None
            self.model_loaded = False
            
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info("âœ… LaMA processor resources cleaned up")
        except Exception as e:
            logger.warning(f"âš ï¸ Error during LaMA processor cleanup: {e}")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥LaMAæ˜¯å¦å¯ç”¨"""
        return self.available and self.model_loaded
'''
    
    with open(lama_fix, 'w') as f:
        f.write(lama_content)
    
    logger.info(f"âœ… åˆ›å»ºä¿®å¤ç‰ˆLaMAå¤„ç†å™¨: {lama_fix}")

def fix_color_space_processing():
    """ä¿®å¤é¢œè‰²ç©ºé—´å¤„ç†é—®é¢˜"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ”§ ä¿®å¤é¢œè‰²ç©ºé—´å¤„ç†...")
    
    # åˆ›å»ºé¢œè‰²ç©ºé—´å¤„ç†å·¥å…·
    color_utils = project_root / "core" / "utils" / "color_utils.py"
    color_content = '''"""
é¢œè‰²ç©ºé—´å¤„ç†å·¥å…·
è§£å†³ä¸åŒæ¨¡å‹çš„é¢œè‰²æ ¼å¼å·®å¼‚
"""

import cv2
import numpy as np
from typing import Dict, Any
import logging

logger = logging.getLogger(__name__)

class ColorSpaceProcessor:
    """é¢œè‰²ç©ºé—´å¤„ç†å™¨"""
    
    @staticmethod
    def prepare_image_for_model(image: np.ndarray, model_name: str) -> np.ndarray:
        """
        æ ¹æ®æ¨¡å‹ç±»å‹å‡†å¤‡å›¾åƒ
        
        Args:
            image: RGBæ ¼å¼çš„è¾“å…¥å›¾åƒ
            model_name: æ¨¡å‹åç§° ('lama', 'zits', 'mat', 'fcf')
            
        Returns:
            å¤„ç†åçš„å›¾åƒæ•°ç»„
        """
        if model_name.lower() == 'lama':
            # LaMAéœ€è¦BGRè¾“å…¥
            return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨RGB
            return image
    
    @staticmethod
    def process_output_for_display(result: np.ndarray, model_name: str) -> np.ndarray:
        """
        å¤„ç†æ¨¡å‹è¾“å‡ºç”¨äºæ˜¾ç¤º
        
        Args:
            result: æ¨¡å‹è¾“å‡ºç»“æœ
            model_name: æ¨¡å‹åç§°
            
        Returns:
            RGBæ ¼å¼çš„å›¾åƒæ•°ç»„
        """
        if model_name.lower() == 'lama':
            # LaMAè¾“å‡ºBGRï¼Œè½¬æ¢ä¸ºRGBæ˜¾ç¤º
            return cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
        else:
            # å…¶ä»–æ¨¡å‹è¾“å‡ºRGB
            return result
    
    @staticmethod
    def validate_color_format(image: np.ndarray, expected_format: str = 'RGB') -> bool:
        """
        éªŒè¯å›¾åƒé¢œè‰²æ ¼å¼
        
        Args:
            image: å›¾åƒæ•°ç»„
            expected_format: æœŸæœ›çš„æ ¼å¼ ('RGB' æˆ– 'BGR')
            
        Returns:
            æ ¼å¼æ˜¯å¦æ­£ç¡®
        """
        if len(image.shape) != 3 or image.shape[2] != 3:
            return False
            
        # ç®€å•çš„é¢œè‰²åˆ†å¸ƒæ£€æŸ¥
        if expected_format == 'RGB':
            # RGBå›¾åƒé€šå¸¸Ré€šé“å€¼è¾ƒé«˜
            return np.mean(image[:, :, 0]) > np.mean(image[:, :, 2])
        else:
            # BGRå›¾åƒé€šå¸¸Bé€šé“å€¼è¾ƒé«˜
            return np.mean(image[:, :, 2]) > np.mean(image[:, :, 0])
    
    @staticmethod
    def fix_color_channels(image: np.ndarray, current_format: str, target_format: str) -> np.ndarray:
        """
        ä¿®å¤é¢œè‰²é€šé“
        
        Args:
            image: è¾“å…¥å›¾åƒ
            current_format: å½“å‰æ ¼å¼
            target_format: ç›®æ ‡æ ¼å¼
            
        Returns:
            ä¿®å¤åçš„å›¾åƒ
        """
        if current_format == target_format:
            return image
            
        if current_format == 'RGB' and target_format == 'BGR':
            return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        elif current_format == 'BGR' and target_format == 'RGB':
            return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            logger.warning(f"Unsupported color conversion: {current_format} -> {target_format}")
            return image

class ModelColorConfig:
    """æ¨¡å‹é¢œè‰²é…ç½®"""
    
    # æ¨¡å‹é¢œè‰²æ ¼å¼é…ç½®
    MODEL_COLOR_CONFIGS = {
        'lama': {
            'input_format': 'BGR',
            'output_format': 'BGR',
            'display_format': 'RGB'
        },
        'zits': {
            'input_format': 'RGB',
            'output_format': 'RGB',
            'display_format': 'RGB'
        },
        'mat': {
            'input_format': 'RGB',
            'output_format': 'RGB',
            'display_format': 'RGB'
        },
        'fcf': {
            'input_format': 'RGB',
            'output_format': 'RGB',
            'display_format': 'RGB'
        }
    }
    
    @classmethod
    def get_model_config(cls, model_name: str) -> Dict[str, str]:
        """è·å–æ¨¡å‹é¢œè‰²é…ç½®"""
        return cls.MODEL_COLOR_CONFIGS.get(model_name.lower(), {
            'input_format': 'RGB',
            'output_format': 'RGB',
            'display_format': 'RGB'
        })
    
    @classmethod
    def prepare_input(cls, image: np.ndarray, model_name: str) -> np.ndarray:
        """å‡†å¤‡æ¨¡å‹è¾“å…¥"""
        config = cls.get_model_config(model_name)
        return ColorSpaceProcessor.prepare_image_for_model(image, model_name)
    
    @classmethod
    def process_output(cls, result: np.ndarray, model_name: str) -> np.ndarray:
        """å¤„ç†æ¨¡å‹è¾“å‡º"""
        config = cls.get_model_config(model_name)
        return ColorSpaceProcessor.process_output_for_display(result, model_name)
'''
    
    with open(color_utils, 'w') as f:
        f.write(color_content)
    
    logger.info(f"âœ… åˆ›å»ºé¢œè‰²ç©ºé—´å¤„ç†å·¥å…·: {color_utils}")

def create_installation_guide():
    """åˆ›å»ºå®‰è£…æŒ‡å—"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ“ åˆ›å»ºå®‰è£…æŒ‡å—...")
    
    guide = project_root / "docs" / "INSTALLATION_GUIDE.md"
    guide_content = '''# WatermarkRemover-AI å®‰è£…æŒ‡å—

## å¿«é€Ÿå®‰è£…

### 1. åŸºç¡€ç¯å¢ƒ
```bash
# å…‹éš†é¡¹ç›®
git clone <repository_url>
cd WatermarkRemover-AI

# åˆ›å»ºcondaç¯å¢ƒ
conda create -n py310aiwatermark python=3.10
conda activate py310aiwatermark

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt
```

### 2. æ¨¡å‹æ–‡ä»¶
é¡¹ç›®å·²åŒ…å«é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ï¼Œæ— éœ€é¢å¤–ä¸‹è½½ã€‚

### 3. å¯é€‰ï¼šLaMAæ”¯æŒ
å¦‚æœéœ€è¦ä½¿ç”¨LaMAæ¨¡å‹ï¼ˆå¿«é€Ÿå¤„ç†ï¼‰ï¼Œå®‰è£…é¢å¤–ä¾èµ–ï¼š
```bash
# æ–¹æ³•1: pipå®‰è£…
pip install saicinpainting

# æ–¹æ³•2: condaå®‰è£…
conda install -c conda-forge saicinpainting
```

## å¯åŠ¨åº”ç”¨

### ä½¿ç”¨ä¼˜åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨CUDAå†…å­˜ä¼˜åŒ–è„šæœ¬
./scripts/set_cuda_env.sh
```

### æ‰‹åŠ¨å¯åŠ¨
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_LAUNCH_BLOCKING=1

# å¯åŠ¨åº”ç”¨
streamlit run interfaces/web/main.py --server.port 8501
```

## æ•…éšœæ’é™¤

### CUDAå†…å­˜ä¸è¶³
1. é™ä½å›¾åƒåˆ†è¾¨ç‡
2. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆZITS â†’ FCF â†’ LaMAï¼‰
3. é‡å¯åº”ç”¨æ¸…ç†æ˜¾å­˜

### LaMAæ¨¡å‹ä¸å¯ç”¨
- æ£€æŸ¥saicinpaintingæ˜¯å¦æ­£ç¡®å®‰è£…
- ä½¿ç”¨å…¶ä»–å¯ç”¨æ¨¡å‹ï¼ˆZITS/MAT/FCFï¼‰

### é¢œè‰²å¼‚å¸¸
- å·²ä¿®å¤é¢œè‰²ç©ºé—´é—®é¢˜
- å¦‚ä»æœ‰é—®é¢˜ï¼Œè¯·æŠ¥å‘Šissue

## æ€§èƒ½ä¼˜åŒ–

### æ˜¾å­˜ç®¡ç†
- ä½¿ç”¨æä¾›çš„CUDAç¯å¢ƒè„šæœ¬
- é¿å…åŒæ—¶åŠ è½½å¤šä¸ªå¤§æ¨¡å‹
- å®šæœŸé‡å¯åº”ç”¨æ¸…ç†æ˜¾å­˜

### å¤„ç†é€Ÿåº¦
- LaMA: æœ€å¿«ï¼ˆ2-5ç§’ï¼‰
- FCF: å¿«é€Ÿï¼ˆ8-20ç§’ï¼‰
- ZITS: ä¸­ç­‰ï¼ˆ10-30ç§’ï¼‰
- MAT: æœ€æ…¢ä½†è´¨é‡æœ€å¥½ï¼ˆ15-45ç§’ï¼‰

## æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æ—¥å¿—è¾“å‡º
2. æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
3. æäº¤issueå¹¶é™„ä¸Šé”™è¯¯ä¿¡æ¯
'''
    
    with open(guide, 'w') as f:
        f.write(guide_content)
    
    logger.info(f"âœ… åˆ›å»ºå®‰è£…æŒ‡å—: {guide}")

def main():
    """ä¸»å‡½æ•°"""
    logger = setup_logging()
    logger.info("ğŸš€ å¼€å§‹åº”ç”¨å¿«é€Ÿä¿®å¤...")
    
    try:
        # 1. ä¿®å¤CUDAå†…å­˜ç®¡ç†
        fix_cuda_memory_management()
        
        # 2. ä¿®å¤LaMAå¤„ç†å™¨
        fix_lama_processor()
        
        # 3. ä¿®å¤é¢œè‰²ç©ºé—´å¤„ç†
        fix_color_space_processing()
        
        # 4. åˆ›å»ºå®‰è£…æŒ‡å—
        create_installation_guide()
        
        logger.info("âœ… æ‰€æœ‰ä¿®å¤å®Œæˆï¼")
        logger.info("ğŸ“‹ ä¿®å¤å†…å®¹:")
        logger.info("  - CUDAå†…å­˜ç®¡ç†ä¼˜åŒ–")
        logger.info("  - LaMAå¯é€‰æ”¯æŒ")
        logger.info("  - é¢œè‰²ç©ºé—´å¤„ç†ä¿®å¤")
        logger.info("  - å®‰è£…æŒ‡å—æ›´æ–°")
        logger.info("")
        logger.info("ğŸš€ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨ä¼˜åŒ–ç‰ˆæœ¬:")
        logger.info("  ./scripts/set_cuda_env.sh")
        
    except Exception as e:
        logger.error(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 