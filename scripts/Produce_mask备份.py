# ----------------- ç¬¬1æ­¥ï¼šå¯¼å…¥åº“ & åŠ è½½æ¨¡å‹ -----------------
import os
import cv2
import numpy as np
import torch
import matplotlib.pyplot as plt
from PIL import Image
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ------------------ å‚æ•°è®¾ç½® ------------------
img_path = "/home/duolaameng/SAM_Remove/Watermark_sam/watermark-segmentation/test/IMG_0095-4.jpg"
ckpt_path = "/home/duolaameng/SAM_Remove/Watermark_sam/output/checkpoints/epoch=071-valid_iou=0.7267.ckpt"
output_dir = os.path.dirname(img_path)

# ------------------ ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•° ------------------
IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD = (0.229, 0.224, 0.225)

# ------------------ ä¸è®­ç»ƒæ—¶ç›¸åŒçš„éªŒè¯æ•°æ®å¢å¼º ------------------
aug_val = A.Compose([
    A.LongestMaxSize(max_size=768),
    A.PadIfNeeded(min_height=768, min_width=768, border_mode=cv2.BORDER_CONSTANT),
    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD, max_pixel_value=255.0),
    ToTensorV2(),
])

# ----------------- ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡å‹å®šä¹‰ -----------------
class WMModel(torch.nn.Module):
    def __init__(self, freeze_encoder=True):
        super().__init__()
        self.net = smp.create_model("FPN", encoder_name="mit_b5", in_channels=3, classes=1)
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
        # PRETRAIN_W = "/home/duolaameng/SAM_Remove/Watermark_sam/watermark-segmentation/best_watermark_model_mit_b5_best.pth"
        # state = torch.load(PRETRAIN_W, map_location="cpu")
        # self.net.load_state_dict(state, strict=False)

        if freeze_encoder:
            for p in self.net.encoder.parameters():
                p.requires_grad = False

    def forward(self, x):
        return self.net(x)

# ------------------ åŠ è½½å›¾åƒ ------------------
image = cv2.imread(img_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
orig_h, orig_w = image_rgb.shape[:2]
print(f"ğŸ–¼ï¸ åŸå›¾å°ºå¯¸: {orig_w} x {orig_h}")

# ---------- æ¨ç†å‰ï¼šç®—å¥½ç¼©æ”¾ & padding ----------
scale = min(768 / orig_h, 768 / orig_w)
new_h, new_w = int(orig_h * scale), int(orig_w * scale)
pad_top, pad_left = (768 - new_h) // 2, (768 - new_w) // 2
print(f"ğŸ“ ç¼©æ”¾æ¯”ä¾‹: {scale:.3f}, ç¼©æ”¾åå°ºå¯¸: {new_w} x {new_h}")
print(f"ğŸ“¦ Padding: top={pad_top}, left={pad_left}")

# ------------------ ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç† ------------------
sample = aug_val(image=image_rgb, mask=None)
img_tensor = sample["image"].unsqueeze(0).to(device)  # [1, 3, H, W]
print(f"ğŸ“¦ é¢„å¤„ç†åå¼ é‡å°ºå¯¸: {img_tensor.shape}")

# ----------------- æ„å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡ -----------------
model = WMModel(freeze_encoder=False).to(device)

# åŠ è½½Lightningæƒé‡
ckpt = torch.load(ckpt_path, map_location=device)
state_dict = {k.replace("net.", ""): v for k, v in ckpt["state_dict"].items() if k.startswith("net.")}
model.net.load_state_dict(state_dict)
model.eval()  # å…³é—­Dropoutå’ŒBatchNormçš„è®­ç»ƒè¡Œä¸º
print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {ckpt_path}")

# ----------------- æ¨ç†å¹¶è¾“å‡ºmask -----------------
with torch.no_grad():
    pred_mask = model(img_tensor)
    pred_mask = torch.sigmoid(pred_mask).squeeze().cpu().numpy()

print(f"ğŸ” é¢„æµ‹maskå°ºå¯¸: {pred_mask.shape}")

# ---------- æ¨ç†åï¼šå…ˆè£ padï¼Œå†ç¼©æ”¾ ----------
print(f"âœ‚ï¸ è£å‰ªpaddingåŒºåŸŸ: [{pad_top}:{pad_top+new_h}, {pad_left}:{pad_left+new_w}]")
pred_crop = pred_mask[pad_top:pad_top+new_h, pad_left:pad_left+new_w]
print(f"ğŸ“ è£å‰ªåå°ºå¯¸: {pred_crop.shape}")

# ç­‰æ¯”ä¾‹ç¼©æ”¾å›åŸå›¾å°ºå¯¸
pred_mask = cv2.resize(pred_crop, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)
print(f"âœ… æœ€ç»ˆmaskå°ºå¯¸: {pred_mask.shape}")

# äºŒå€¼åŒ– & è†¨èƒ€
binary_mask = (pred_mask > 0.5).astype(np.uint8) * 255
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
dilated_mask = cv2.dilate(binary_mask, kernel, iterations=1)

# ä¿å­˜ç»“æœ
base_name = os.path.splitext(os.path.basename(img_path))[0]
binary_mask_path = os.path.join(output_dir, f"{base_name}_binary_mask.png")
dilated_mask_path = os.path.join(output_dir, f"{base_name}_dilated_mask.png")
raw_mask_path = os.path.join(output_dir, f"{base_name}_raw_mask.png")

cv2.imwrite(binary_mask_path, binary_mask)
cv2.imwrite(dilated_mask_path, dilated_mask)
cv2.imwrite(raw_mask_path, (pred_mask * 255).astype(np.uint8))

print(f"âœ… Saved: {binary_mask_path}")
print(f"âœ… Saved: {dilated_mask_path}")
print(f"âœ… Saved: {raw_mask_path}")

# æ˜¾ç¤ºç»“æœ
plt.figure(figsize=(15, 5))
plt.subplot(1, 4, 1)
plt.imshow(image_rgb)
plt.title("Original Image")
plt.axis('off')

plt.subplot(1, 4, 2)
plt.imshow(pred_mask, cmap='gray')
plt.title("Raw Prediction")
plt.axis('off')

plt.subplot(1, 4, 3)
plt.imshow(binary_mask, cmap='gray')
plt.title("Binary Mask")
plt.axis('off')

plt.subplot(1, 4, 4)
plt.imshow(dilated_mask, cmap='gray')
plt.title("Dilated Mask")
plt.axis('off')

plt.tight_layout()
plt.savefig(os.path.join(output_dir, f"{base_name}_results.png"), dpi=150, bbox_inches='tight')
plt.show()
