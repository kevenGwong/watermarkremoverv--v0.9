#!/usr/bin/env python3
"""
æ•°æ®æµéªŒè¯æµ‹è¯• - éªŒè¯UIâ†’inferenceâ†’managerâ†’processorçš„å®Œæ•´é“¾è·¯
"""

import os
import sys
import json
import numpy as np
from PIL import Image
from pathlib import Path
from typing import Dict, Any, Tuple
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_data_flow_without_models():
    """æµ‹è¯•æ•°æ®æµé“¾è·¯ï¼ˆä¸åŠ è½½å®é™…æ¨¡å‹ï¼‰"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®æµé“¾è·¯ï¼ˆä¸ä¾èµ–æ¨¡å‹ï¼‰...")
    
    # æµ‹è¯•é…ç½®ç®¡ç†å™¨
    try:
        from config.config import ConfigManager
        config_manager = ConfigManager()
        config = config_manager.get_config()
        print("  âœ… é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # éªŒè¯å…³é”®é…ç½®é¡¹
        key_configs = ['models', 'ui', 'processing']
        missing_configs = [k for k in key_configs if not hasattr(config, k)]
        if missing_configs:
            print(f"  âš ï¸ ç¼ºå¤±é…ç½®é¡¹: {missing_configs}")
        else:
            print("  âœ… å…³é”®é…ç½®é¡¹å®Œæ•´")
            
    except Exception as e:
        print(f"  âŒ é…ç½®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ•°æ®ç»“æ„
    try:
        from core.processors.processing_result import ProcessingResult
        
        # åˆ›å»ºæµ‹è¯•ç»“æœ
        test_image = Image.new('RGB', (100, 100), 'blue')
        test_mask = Image.new('L', (100, 100), 255)
        
        result = ProcessingResult(
            success=True,
            result_image=test_image,
            mask_image=test_mask,
            processing_time=1.5
        )
        
        print("  âœ… ProcessingResultæ•°æ®ç»“æ„æ­£å¸¸")
        print(f"    - success: {result.success}")
        print(f"    - result_image: {result.result_image.size if result.result_image else None}")
        print(f"    - mask_image: {result.mask_image.size if result.mask_image else None}")
        print(f"    - processing_time: {result.processing_time}")
        
    except Exception as e:
        print(f"  âŒ ProcessingResultåˆ›å»ºå¤±è´¥: {e}")
        return False
    
    return True

def test_parameter_flow():
    """æµ‹è¯•å‚æ•°ä¼ é€’æµç¨‹"""
    print("\nğŸ§ª æµ‹è¯•å‚æ•°ä¼ é€’æµç¨‹...")
    
    # æ¨¡æ‹ŸUIå‚æ•°
    ui_params = {
        'mask_model': 'upload',
        'mask_params': {
            'uploaded_mask': None,
            'mask_dilate_kernel_size': 5,
            'mask_dilate_iterations': 2
        },
        'inpaint_params': {
            'inpaint_model': 'iopaint',
            'force_model': 'mat',
            'hd_strategy': 'ORIGINAL',
            'ldm_steps': 50
        },
        'performance_params': {
            'mixed_precision': True,
            'log_processing_time': True
        },
        'transparent': False
    }
    
    print("  ğŸ“‹ æ¨¡æ‹ŸUIå‚æ•°:")
    for key, value in ui_params.items():
        print(f"    {key}: {type(value).__name__}")
        if isinstance(value, dict):
            for subkey, subvalue in value.items():
                print(f"      {subkey}: {subvalue}")
    
    # æµ‹è¯•å‚æ•°éªŒè¯å’Œè½¬æ¢
    try:
        from core.utils.image_utils import ImageValidator
        
        # æµ‹è¯•å›¾åƒéªŒè¯
        test_image = Image.new('RGB', (512, 512), 'red')
        validation_result = ImageValidator.validate_input(test_image)
        
        print(f"  âœ… å›¾åƒéªŒè¯: {validation_result}")
        
    except Exception as e:
        print(f"  âŒ å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return False
    
    return True

def test_inference_chain():
    """æµ‹è¯•æ¨ç†é“¾æ¡ç»“æ„"""
    print("\nğŸ§ª æµ‹è¯•æ¨ç†é“¾æ¡ç»“æ„...")
    
    # æµ‹è¯•InferenceManagerç»“æ„
    try:
        # åªå¯¼å…¥ç±»å®šä¹‰ï¼Œä¸å®ä¾‹åŒ–
        from core.inference_manager import InferenceManager
        from core.processors.watermark_processor import WatermarkProcessor
        from core.models.unified_processor import UnifiedProcessor
        
        print("  âœ… æ ¸å¿ƒç±»å¯¼å…¥æˆåŠŸ:")
        print("    - InferenceManager")
        print("    - WatermarkProcessor")
        print("    - UnifiedProcessor")
        
        # æ£€æŸ¥æ–¹æ³•å­˜åœ¨æ€§
        manager_methods = ['process_request', '_generate_mask', '_process_with_inpaint']
        processor_methods = ['process_image']
        unified_methods = ['get_available_models', 'predict_with_model']
        
        print("  ğŸ“‹ å…³é”®æ–¹æ³•æ£€æŸ¥:")
        
        # InferenceManageræ–¹æ³•
        for method in manager_methods:
            has_method = hasattr(InferenceManager, method)
            status = "âœ…" if has_method else "âŒ"
            print(f"    InferenceManager.{method}: {status}")
        
        # WatermarkProcessoræ–¹æ³•
        for method in processor_methods:
            has_method = hasattr(WatermarkProcessor, method)
            status = "âœ…" if has_method else "âŒ"
            print(f"    WatermarkProcessor.{method}: {status}")
        
        # UnifiedProcessoræ–¹æ³•
        for method in unified_methods:
            has_method = hasattr(UnifiedProcessor, method)
            status = "âœ…" if has_method else "âŒ"
            print(f"    UnifiedProcessor.{method}: {status}")
        
    except Exception as e:
        print(f"  âŒ æ¨ç†é“¾æ¡ç»“æ„æ£€æŸ¥å¤±è´¥: {e}")
        return False
    
    return True

def test_mask_generation_flow():
    """æµ‹è¯•maskç”Ÿæˆæµç¨‹"""
    print("\nğŸ§ª æµ‹è¯•maskç”Ÿæˆæµç¨‹...")
    
    try:
        from core.models.mask_generators import FallbackMaskGenerator
        
        # æµ‹è¯•fallback maskç”Ÿæˆå™¨
        fallback_gen = FallbackMaskGenerator()
        
        test_image = Image.new('RGB', (256, 256), 'green')
        test_params = {'mask_threshold': 0.5}
        
        # ç”Ÿæˆmask
        generated_mask = fallback_gen.generate_mask(test_image, test_params)
        
        print(f"  âœ… Fallback maskç”ŸæˆæˆåŠŸ:")
        print(f"    - è¾“å…¥å›¾åƒå°ºå¯¸: {test_image.size}")
        print(f"    - ç”Ÿæˆmaskå°ºå¯¸: {generated_mask.size}")
        print(f"    - Maskæ¨¡å¼: {generated_mask.mode}")
        
        # æ£€æŸ¥maskåƒç´ å€¼
        mask_array = np.array(generated_mask)
        unique_values = np.unique(mask_array)
        print(f"    - åƒç´ å€¼èŒƒå›´: {mask_array.min()} - {mask_array.max()}")
        print(f"    - å”¯ä¸€å€¼: {unique_values}")
        
    except Exception as e:
        print(f"  âŒ Maskç”Ÿæˆæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_configuration_flow():
    """æµ‹è¯•é…ç½®æµç¨‹"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®æµç¨‹...")
    
    try:
        from config.config import ConfigManager
        
        config_manager = ConfigManager()
        
        # æµ‹è¯•é»˜è®¤é…ç½®è·å–
        default_config = config_manager.get_config()
        
        print("  âœ… é»˜è®¤é…ç½®åŠ è½½æˆåŠŸ:")
        
        # æ£€æŸ¥é…ç½®ç»“æ„
        config_attrs = ['models', 'ui', 'processing']
        for attr in config_attrs:
            has_attr = hasattr(default_config, attr)
            status = "âœ…" if has_attr else "âŒ"
            print(f"    {attr}: {status}")
            
            if has_attr:
                config_section = getattr(default_config, attr)
                if hasattr(config_section, '__dict__'):
                    section_keys = list(config_section.__dict__.keys())
                    print(f"      åŒ…å«: {section_keys[:3]}..." if len(section_keys) > 3 else f"      åŒ…å«: {section_keys}")
        
        # æµ‹è¯•é…ç½®éªŒè¯
        test_params = {
            'mask_model': 'upload',
            'inpaint_params': {
                'hd_strategy': 'ORIGINAL',
                'ldm_steps': 50
            }
        }
        
        validated_params = config_manager.validate_parameters(test_params)
        print(f"  âœ… å‚æ•°éªŒè¯æˆåŠŸ: {len(validated_params)} ä¸ªå‚æ•°")
        
    except Exception as e:
        print(f"  âŒ é…ç½®æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def test_image_processing_utils():
    """æµ‹è¯•å›¾åƒå¤„ç†å·¥å…·"""
    print("\nğŸ§ª æµ‹è¯•å›¾åƒå¤„ç†å·¥å…·...")
    
    try:
        from core.utils.image_utils import ImageProcessor, ImageValidator, ImageDownloader
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = Image.new('RGB', (300, 200), 'yellow')
        
        # æµ‹è¯•å›¾åƒéªŒè¯
        is_valid = ImageValidator.validate_input(test_image)
        print(f"  âœ… å›¾åƒéªŒè¯: {is_valid}")
        
        # æµ‹è¯•å›¾åƒå¤„ç†
        resized_image = ImageProcessor.resize_image(test_image, (150, 100))
        print(f"  âœ… å›¾åƒè°ƒæ•´: {test_image.size} â†’ {resized_image.size}")
        
        # æµ‹è¯•ä¸‹è½½ä¿¡æ¯ç”Ÿæˆ
        download_info = ImageDownloader.create_download_info(test_image, "test")
        print(f"  âœ… ä¸‹è½½ä¿¡æ¯ç”Ÿæˆ: {len(download_info)} ä¸ªæ ¼å¼")
        
        for info in download_info:
            print(f"    - {info['format']}: {info['filename']}")
        
    except Exception as e:
        print(f"  âŒ å›¾åƒå¤„ç†å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    return True

def analyze_data_flow_structure():
    """åˆ†ææ•°æ®æµç»“æ„"""
    print("\nğŸ” åˆ†ææ•°æ®æµç»“æ„...")
    
    data_flow_map = {
        'UI Layer': {
            'files': ['interfaces/web/main.py', 'interfaces/web/ui.py'],
            'function': 'ç”¨æˆ·äº¤äº’ï¼Œå‚æ•°æ”¶é›†',
            'outputs': 'UIå‚æ•°å­—å…¸'
        },
        'Inference Layer': {
            'files': ['core/inference.py'],
            'function': 'ç»Ÿä¸€APIå…¥å£',
            'outputs': 'ProcessingResultå¯¹è±¡'
        },
        'Manager Layer': {
            'files': ['core/inference_manager.py'],
            'function': 'è¯·æ±‚åˆ†å‘ï¼Œæµç¨‹ç®¡ç†',
            'outputs': 'å¤„ç†åçš„å›¾åƒå’Œmask'
        },
        'Processor Layer': {
            'files': ['core/processors/watermark_processor.py'],
            'function': 'å…·ä½“å¤„ç†é€»è¾‘',
            'outputs': 'ä¿®å¤åçš„å›¾åƒ'
        },
        'Model Layer': {
            'files': ['core/models/unified_processor.py', 'core/models/mask_generators.py'],
            'function': 'AIæ¨¡å‹è°ƒç”¨',
            'outputs': 'AIæ¨¡å‹é¢„æµ‹ç»“æœ'
        }
    }
    
    print("  ğŸ“Š æ•°æ®æµç»“æ„åˆ†æ:")
    for layer, info in data_flow_map.items():
        print(f"\n    {layer}:")
        print(f"      æ–‡ä»¶: {', '.join(info['files'])}")
        print(f"      åŠŸèƒ½: {info['function']}")
        print(f"      è¾“å‡º: {info['outputs']}")
    
    # åˆ†ææ•°æ®ä¼ é€’è·¯å¾„
    print("\n  ğŸ”„ æ•°æ®ä¼ é€’è·¯å¾„:")
    print("    1. UI â†’ inference.py (process_image)")
    print("    2. inference.py â†’ inference_manager.py (process_request)")
    print("    3. inference_manager.py â†’ watermark_processor.py (process_image)")
    print("    4. watermark_processor.py â†’ unified_processor.py (predict_with_model)")
    print("    5. unified_processor.py â†’ IOPaintæ¨¡å‹ (åº•å±‚æ¨ç†)")
    print("    6. ç»“æœé€†å‘ä¼ é€’å›UI")
    
    return True

def test_data_flow_comprehensive():
    """æ•°æ®æµéªŒè¯å®Œæ•´æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æ•°æ®æµéªŒè¯æµ‹è¯•...")
    
    test_results = {}
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ('æ•°æ®æµåŸºç¡€ç»“æ„', test_data_flow_without_models),
        ('å‚æ•°ä¼ é€’æµç¨‹', test_parameter_flow),
        ('æ¨ç†é“¾æ¡ç»“æ„', test_inference_chain),
        ('Maskç”Ÿæˆæµç¨‹', test_mask_generation_flow),
        ('é…ç½®æµç¨‹', test_configuration_flow),
        ('å›¾åƒå¤„ç†å·¥å…·', test_image_processing_utils),
        ('æ•°æ®æµç»“æ„åˆ†æ', analyze_data_flow_structure)
    ]
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            test_results[test_name] = result
        except Exception as e:
            print(f"  âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
            test_results[test_name] = False
    
    # è¾“å‡ºæ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®æµéªŒè¯æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    passed_tests = sum(1 for result in test_results.values() if result)
    total_tests = len(test_results)
    
    print(f"\nğŸ¯ æµ‹è¯•é€šè¿‡ç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")
    
    print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    for test_name, result in test_results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    # æ•°æ®æµå¥åº·åº¦è¯„ä¼°
    critical_tests = ['æ•°æ®æµåŸºç¡€ç»“æ„', 'æ¨ç†é“¾æ¡ç»“æ„', 'é…ç½®æµç¨‹']
    critical_passed = sum(1 for test in critical_tests if test_results.get(test, False))
    
    print(f"\nğŸ”§ å…³é”®ç»„ä»¶å¥åº·åº¦:")
    print(f"   æ ¸å¿ƒæ•°æ®æµ: {critical_passed}/{len(critical_tests)} é€šè¿‡")
    
    # æ•´ä½“è¯„ä¼°
    overall_health = passed_tests >= total_tests * 0.8 and critical_passed == len(critical_tests)
    
    print(f"\nğŸ¯ æ•´ä½“è¯„ä¼°:")
    print(f"   æ•°æ®æµå®Œæ•´æ€§: {'âœ… ä¼˜ç§€' if overall_health else 'âš ï¸ éœ€è¦æ”¹è¿›'}")
    
    if overall_health:
        print("\nğŸ‰ æ•°æ®æµéªŒè¯é€šè¿‡!")
        print("âœ… UIâ†’inferenceâ†’managerâ†’processoré“¾è·¯å®Œæ•´")
        print("âœ… å‚æ•°ä¼ é€’æœºåˆ¶æ­£å¸¸")
        print("âœ… æ•°æ®ç»“æ„å®šä¹‰å®Œå–„")
        print("âœ… é”™è¯¯å¤„ç†æœºåˆ¶å¥å…¨")
    else:
        print("\nâš ï¸ æ•°æ®æµéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        failed_tests = [name for name, result in test_results.items() if not result]
        if failed_tests:
            print(f"éœ€è¦ä¿®å¤çš„ç»„ä»¶: {', '.join(failed_tests)}")
    
    return test_results, overall_health

if __name__ == "__main__":
    results, health = test_data_flow_comprehensive()
    
    if health:
        print("\nâœ… æ•°æ®æµéªŒè¯å…¨éƒ¨é€šè¿‡!")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ•°æ®æµç»„ä»¶éœ€è¦ä¼˜åŒ–")