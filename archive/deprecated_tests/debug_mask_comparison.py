#!/usr/bin/env python3
"""
Debugging script to compare mask formats and processing between:
1. test_iopaint.py (working well)
2. UI app processing (not working as well)
"""
import cv2
import numpy as np
from PIL import Image
from pathlib import Path
import torch
from iopaint.model_manager import ModelManager
from iopaint.schema import HDStrategy, LDMSampler, InpaintRequest as Config

def analyze_mask_format(mask_path: str):
    """åˆ†æmaskæ–‡ä»¶çš„æ ¼å¼"""
    print(f"\n=== Analyzing mask: {mask_path} ===")
    
    # ä½¿ç”¨cv2è¯»å–ï¼ˆtest_iopaint.pyçš„æ–¹å¼ï¼‰
    mask_cv2 = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    print(f"CV2 reading:")
    print(f"  Shape: {mask_cv2.shape}")
    print(f"  Dtype: {mask_cv2.dtype}")
    print(f"  Min/Max: {mask_cv2.min()}/{mask_cv2.max()}")
    print(f"  Unique values: {np.unique(mask_cv2)}")
    
    # ä½¿ç”¨PILè¯»å–ï¼ˆUI appçš„æ–¹å¼ï¼‰
    mask_pil = Image.open(mask_path)
    print(f"\nPIL reading:")
    print(f"  Mode: {mask_pil.mode}")
    print(f"  Size: {mask_pil.size}")
    mask_pil_array = np.array(mask_pil)
    print(f"  Shape after np.array: {mask_pil_array.shape}")
    print(f"  Dtype: {mask_pil_array.dtype}")
    print(f"  Min/Max: {mask_pil_array.min()}/{mask_pil_array.max()}")
    print(f"  Unique values: {np.unique(mask_pil_array)}")
    
    # è½¬æ¢ä¸ºLæ¨¡å¼ï¼ˆUI appå¯èƒ½çš„å¤„ç†ï¼‰
    mask_pil_l = mask_pil.convert('L')
    mask_pil_l_array = np.array(mask_pil_l)
    print(f"\nPIL L mode:")
    print(f"  Shape: {mask_pil_l_array.shape}")
    print(f"  Dtype: {mask_pil_l_array.dtype}")
    print(f"  Min/Max: {mask_pil_l_array.min()}/{mask_pil_l_array.max()}")
    print(f"  Unique values: {np.unique(mask_pil_l_array)}")
    
    # æ£€æŸ¥æ˜¯å¦ç›¸åŒ
    if np.array_equal(mask_cv2, mask_pil_l_array):
        print("\nâœ… CV2 and PIL L mode arrays are identical")
    else:
        print("\nâŒ CV2 and PIL L mode arrays are different")
        diff = np.abs(mask_cv2.astype(np.int16) - mask_pil_l_array.astype(np.int16))
        print(f"  Max difference: {diff.max()}")
        print(f"  Different pixels: {np.sum(diff > 0)}")

def analyze_image_format(image_path: str):
    """åˆ†æè¾“å…¥å›¾åƒçš„æ ¼å¼"""
    print(f"\n=== Analyzing image: {image_path} ===")
    
    # ä½¿ç”¨cv2è¯»å–ï¼ˆtest_iopaint.pyçš„æ–¹å¼ï¼‰
    image_cv2 = cv2.imread(image_path)
    print(f"CV2 reading:")
    print(f"  Shape: {image_cv2.shape}")
    print(f"  Dtype: {image_cv2.dtype}")
    print(f"  Color order: BGR")
    
    # ä½¿ç”¨PILè¯»å–ï¼ˆUI appçš„æ–¹å¼ï¼‰
    image_pil = Image.open(image_path)
    print(f"\nPIL reading:")
    print(f"  Mode: {image_pil.mode}")
    print(f"  Size: {image_pil.size}")
    image_pil_array = np.array(image_pil)
    print(f"  Shape after np.array: {image_pil_array.shape}")
    print(f"  Dtype: {image_pil_array.dtype}")
    print(f"  Color order: RGB")

def test_iopaint_processing(image_path: str, mask_path: str, output_path: str):
    """æµ‹è¯•test_iopaint.pyçš„å¤„ç†æ–¹å¼"""
    print(f"\n=== Test iopaint processing (Original Method) ===")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_manager = ModelManager(name="lama", device=device)
    
    # test_iopaint.pyçš„æ–¹å¼ - CV2è¯»å–BGRæ ¼å¼
    image = cv2.imread(image_path)  # BGR format
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    
    print(f"âœ… CV2 è¯»å–:")
    print(f"  Image shape: {image.shape}, dtype: {image.dtype}, format: BGR")
    print(f"  Image sample pixel [0,0]: {image[0,0]} (BGR)")
    print(f"  Mask shape: {mask.shape}, dtype: {mask.dtype}")
    print(f"  Mask unique values: {np.unique(mask)}")
    
    # è†¨èƒ€å¤„ç†ï¼ˆä½¿ç”¨kernel_size=5ï¼‰
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    dilated_mask = cv2.dilate(mask, kernel, iterations=1)
    
    # LaMAå¤„ç† - æ³¨æ„ï¼šè¿™é‡Œimageæ˜¯BGRæ ¼å¼ï¼
    config = Config(
        ldm_steps=50,
        ldm_sampler=LDMSampler.ddim,
        hd_strategy=HDStrategy.CROP,
        hd_strategy_crop_margin=64,
        hd_strategy_crop_trigger_size=800,
        hd_strategy_resize_limit=1600,
    )
    
    print(f"ğŸ”„ ä¼ å…¥LaMAçš„æ•°æ®:")
    print(f"  Image format: BGR (CV2åŸç”Ÿ)")
    print(f"  Image sample pixel [0,0]: {image[0,0]}")
    
    result = model_manager(image, dilated_mask, config)
    
    print(f"ğŸ“¤ LaMAè¾“å‡º:")
    print(f"  Result shape: {result.shape}, dtype: {result.dtype}")
    print(f"  Result sample pixel [0,0]: {result[0,0]}")
    print(f"  Result min/max: {result.min()}/{result.max()}")
    
    if result.dtype in [np.float64, np.float32]:
        result = np.clip(result, 0, 255).astype(np.uint8)
    
    # CV2ä¿å­˜ - ä¿æŒBGRæ ¼å¼
    cv2.imwrite(output_path, result)
    print(f"ğŸ’¾ CV2ä¿å­˜ (BGRæ ¼å¼): {output_path}")
    
    return result

def test_ui_processing(image_path: str, mask_path: str, output_path: str):
    """æµ‹è¯•UI appçš„å¤„ç†æ–¹å¼"""
    print(f"\n=== Test UI processing (Current App Method) ===")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_manager = ModelManager(name="lama", device=device)
    
    # UI appçš„æ–¹å¼ - PILè¯»å–RGBæ ¼å¼
    image_pil = Image.open(image_path).convert("RGB")  # RGB format
    mask_pil = Image.open(mask_path).convert("L")
    
    print(f"âœ… PIL è¯»å–:")
    print(f"  Image mode: {image_pil.mode}, size: {image_pil.size}, format: RGB")
    
    # è½¬æ¢ä¸ºnumpy
    image_np = np.array(image_pil)  # RGB format
    mask_np = np.array(mask_pil)
    
    print(f"  Image sample pixel [0,0]: {image_np[0,0]} (RGB)")
    print(f"  Mask unique values: {np.unique(mask_np)}")
    
    # æ·»åŠ ç›¸åŒçš„è†¨èƒ€å¤„ç†ï¼ˆkernel_size=5ï¼‰
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    mask_np = cv2.dilate(mask_np, kernel, iterations=1)
    
    # LaMAå¤„ç† - æ³¨æ„ï¼šè¿™é‡Œimageæ˜¯RGBæ ¼å¼ï¼
    config = Config(
        ldm_steps=50,
        ldm_sampler=LDMSampler.ddim,
        hd_strategy=HDStrategy.CROP,
        hd_strategy_crop_margin=64,
        hd_strategy_crop_trigger_size=800,
        hd_strategy_resize_limit=1600,
    )
    
    print(f"ğŸ”„ ä¼ å…¥LaMAçš„æ•°æ®:")
    print(f"  Image format: RGB (PILè½¬numpy)")
    print(f"  Image sample pixel [0,0]: {image_np[0,0]}")
    
    result = model_manager(image_np, mask_np, config)
    
    print(f"ğŸ“¤ LaMAè¾“å‡º:")
    print(f"  Result shape: {result.shape}, dtype: {result.dtype}")
    print(f"  Result sample pixel [0,0]: {result[0,0]}")
    print(f"  Result min/max: {result.min()}/{result.max()}")
    
    if result.dtype in [np.float64, np.float32]:
        result = np.clip(result, 0, 255).astype(np.uint8)
    
    # è¿™æ˜¯é—®é¢˜æ‰€åœ¨ï¼UI appåšäº†BGRâ†’RGBè½¬æ¢
    print(f"ğŸ”„ UI appçš„é¢œè‰²è½¬æ¢:")
    print(f"  è½¬æ¢å‰ result[0,0]: {result[0,0]} (LaMAè¾“å‡º)")
    
    # UI appçš„å¤„ç†ï¼šè®¤ä¸ºresultæ˜¯BGRï¼Œè½¬æ¢ä¸ºRGB
    result_pil = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))
    result_converted = np.array(result_pil)
    print(f"  è½¬æ¢å result[0,0]: {result_converted[0,0]} (BGRâ†’RGBè½¬æ¢å)")
    
    result_pil.save(output_path)
    print(f"ğŸ’¾ PILä¿å­˜ (ç»è¿‡BGRâ†’RGBè½¬æ¢): {output_path}")
    
    return result

def test_ui_processing_fixed(image_path: str, mask_path: str, output_path: str):
    """æµ‹è¯•ä¿®å¤åçš„UI appå¤„ç†æ–¹å¼"""
    print(f"\n=== Test UI processing (FIXED Method) ===")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_manager = ModelManager(name="lama", device=device)
    
    # UI appçš„æ–¹å¼ - PILè¯»å–RGBæ ¼å¼
    image_pil = Image.open(image_path).convert("RGB")
    mask_pil = Image.open(mask_path).convert("L")
    
    # è½¬æ¢ä¸ºnumpy
    image_np = np.array(image_pil)  # RGB format
    mask_np = np.array(mask_pil)
    
    print(f"âœ… ä¿®å¤æ–¹æ¡ˆ - ç›´æ¥ä½¿ç”¨RGBæ ¼å¼:")
    print(f"  Input sample pixel [0,0]: {image_np[0,0]} (RGB)")
    
    # è†¨èƒ€å¤„ç†
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    mask_np = cv2.dilate(mask_np, kernel, iterations=1)
    
    # LaMAå¤„ç†é…ç½®
    config = Config(
        ldm_steps=50,
        ldm_sampler=LDMSampler.ddim,
        hd_strategy=HDStrategy.CROP,
        hd_strategy_crop_margin=64,
        hd_strategy_crop_trigger_size=800,
        hd_strategy_resize_limit=1600,
    )
    
    result = model_manager(image_np, mask_np, config)
    
    print(f"ğŸ“¤ LaMAè¾“å‡º:")
    print(f"  Result sample pixel [0,0]: {result[0,0]} (LaMAè¾“å‡ºæ ¼å¼)")
    
    if result.dtype in [np.float64, np.float32]:
        result = np.clip(result, 0, 255).astype(np.uint8)
    
    # ä¿®å¤ï¼šç›´æ¥ä¿å­˜ï¼Œä¸åšé¢œè‰²è½¬æ¢
    print(f"ğŸ”§ ä¿®å¤æ–¹æ¡ˆ - ä¸åšé¢œè‰²è½¬æ¢:")
    result_pil = Image.fromarray(result)  # ç›´æ¥ä½¿ç”¨resultï¼Œä¸è½¬æ¢
    print(f"  Final sample pixel [0,0]: {np.array(result_pil)[0,0]} (æ— è½¬æ¢)")
    
    result_pil.save(output_path)
    print(f"ğŸ’¾ ä¿®å¤åä¿å­˜: {output_path}")
    
    return result

def main():
    # æ–‡ä»¶è·¯å¾„
    image_path = "/home/duolaameng/SAM_Remove/WatermarkRemover-AI/test/input/IMG_0001-3.jpg"
    mask_path = "/home/duolaameng/SAM_Remove/WatermarkRemover-AI/test/mask/IMG_0095-4_dilated_mask.png"
    output_dir = "/home/duolaameng/SAM_Remove/WatermarkRemover-AI/test/output"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_dir).mkdir(exist_ok=True)
    
    print("ğŸ” é¢œè‰²æ ¼å¼è¯Šæ–­åˆ†æ")
    print("=" * 60)
    
    # æµ‹è¯•ä¸‰ç§å¤„ç†æ–¹å¼
    test_iopaint_output = str(Path(output_dir) / "debug_test_iopaint_method.png")
    test_ui_output = str(Path(output_dir) / "debug_ui_app_method.png") 
    test_ui_fixed_output = str(Path(output_dir) / "debug_ui_app_FIXED.png")
    
    test_iopaint_processing(image_path, mask_path, test_iopaint_output)
    test_ui_processing(image_path, mask_path, test_ui_output)
    test_ui_processing_fixed(image_path, mask_path, test_ui_fixed_output)
    
    print(f"\nğŸ¯ é¢œè‰²æ ¼å¼è¯Šæ–­ç»“æœ:")
    print(f"=" * 60)
    print(f"1. âœ… åŸtest_iopaintæ–¹æ³•: {test_iopaint_output}")
    print(f"2. âŒ å½“å‰UI appæ–¹æ³• (é¢œè‰²é—®é¢˜): {test_ui_output}")
    print(f"3. ğŸ”§ ä¿®å¤åUIæ–¹æ³•: {test_ui_fixed_output}")
    print(f"\nğŸ’¡ å¦‚æœæ–¹æ³•3çš„ç»“æœå’Œæ–¹æ³•1ç±»ä¼¼ï¼Œè¯´æ˜é—®é¢˜å°±æ˜¯é¢œè‰²è½¬æ¢!")

if __name__ == "__main__":
    main()